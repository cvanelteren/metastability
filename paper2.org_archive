#    -*- mode: org -*-


Archived entries from file /home/casper/papers/paper2/paper2.org


* Introduction - Version 2 :noexport:
:PROPERTIES:
:ARCHIVE_TIME: 2022-01-19 Wed 09:14
:ARCHIVE_FILE: ~/papers/paper2/paper2.org
:ARCHIVE_CATEGORY: paper2
:END:
Hysteresis is the dependence of the state of a system on its
history.  For  example, a  magnet  may  have more  than  one
possible  magnetic   moment  in  a  given   magnetic  field,
depending on how  the field changed in the  past. In natural
systems  hysteresis is  often  associated with  irreversible
thermodynamic change  such as phase transitions  or internal
friction.  These  are  colloquially called  tipping  points.
Tipping point analysis has  gained major attention is recent
years  in  understanding how  and  why  complex systems  may
undergo  these  rapid  transition from  a  common  seemingly
stable behavior to a different equilibrium. Examples include
tipping points in  climate systems, ecosystems, polarization
dynamics and so on.


* Old :noexport:
:PROPERTIES:
:ARCHIVE_TIME: 2022-01-19 Wed 09:14
:ARCHIVE_FILE: ~/papers/paper2/paper2.org
:ARCHIVE_CATEGORY: paper2
:END:
** Detecting transition probabilities of nodes
Semi-mean field approximation;
Each  node only  depends on  its  neighbors, as  such  we can  compute the  flip
probability for  each degree  based on the  possible configurations.  Every node
flip will  contribute equal  to the  transition to and  from the  tipping point.
However, the  flip of a node  at some time $t$  may influence other nodes  to be
more likely to flip at $t + 1$.


*Goal*: find the probability  of a node $s_i \in S$ assuming a  new state $s_i =
x'$ given that its neighborhood has one flipped node.

Let $S =  \{s_1, \dots, s_n\}$ be  a set of random variables  each with alphabet
$s_i \in A$. The configuration of the system follows the Gibbs distribution

#+name:
\begin{equation}
p(S) = \frac{1}{Z}\exp(-\beta (H (S) )
\end{equation}

with  $\beta  = \frac{1}{KT}$  with  $k$  as  the  Boltzmann constant,  $Z$  the
partition function and $\mathbb{H}$ the  Hamiltonian function of the system. To
measure the effect of  the change for spin $s_i$ from $x$ to  $x'$ as a function
of a flip that occurs in the neighbors of $s_i$, we define the change ratio as:

#+name:
\begin{equation}
\begin{aligned}
cr(s_i)_{x \rightarrow x'} &= \sum_{S_i, S_i' \in S} \sum_{x, x' \in A} \frac{a(x, s_i = x', S_i)}{a(x, s_i = x', S_i')} \frac{p(S_i)}{p(S_i')}\\
a(x, x', X) &= \frac{p(x' | X)}{p(x | X)}
\end{aligned}
\end{equation}

where $S_i \in  S$ is a system  configuration and $S_i'$ is a  system change for
which one of the neighbors of $s_i$ is flipped compared to $S_i$.

*** Nudge effect as a function of degree
Hamiltonian $\mathbb{H}$ controls the probability  of assuming some state $x\in
A$ for any node  $s_i$. The range of the $\mathbb{H}$ will  vary as function of
the degree  of node. For  example for  a standard lattice,  $\mathbb{H}$ varies
between  $-4  <  \mathbb{H}(S)  <  4$  $\forall s_i  \in  S$.  We  rewrite  the
Hamiltonian as

#+name:
\begin{equation}
\mathbb{H}(S) = \sum k_i
\end{equation}

# where $s'_j \in L_i \subseteq S$ is  in the nearest neighbors of node $s_i$, $K$
# is a random variable representing the degrees in the system.


**** Magnetized neighbors
Let the system $S$  be in the fully aligned state, i.e. $s_i  = s_j \forall s_i,
s_j \in S$. The Hamiltonian for the system can be written as:

#+name:
\begin{equation}
H(s_k) =  k,
\end{equation}

where $s_k$ is a node with degree $k$.

If any one  node is flipped with  respect to its neighbor,  the acceptance ratio
will be:
#+name:
\begin{equation}
a(x, x', X) = \frac{p(x' | X)}{p(x | X)} = \frac{1}{1+\exp(-2 \beta
 k)}.
\end{equation}

As a  function of  $\beta \rightarrow \infty$,  the acceptance  probability will
diverge. That is as the temperature decreases, it will become less likely that a
node switches to  the opposite state $x'$. In addition,  the degree interacts in
such a way that  as $k$ increases for a given $\beta$,  higher degree nodes will
be less likely to flip as $k$ increases.

#+begin_src jupyter-python
from matplotlib import style; style.use("fivethirtyeight".split())
import matplotlib.pyplot as plt, cmasher as cmr
import numpy as np, os, sys, networkx as nx, warnings
warnings.simplefilter("ignore")

H = lambda k: - k
energy = lambda k, beta:  np.exp(- beta * h(k - 2))
k = np.arange(1, 5)

b = np.linspace(0.1, 10, 1000)
beta, ks = np.meshgrid(k, b)
fig, ax = plt.subplots()
z = energy(ks, beta)
h = ax.imshow(z, aspect = 'auto',
          extent = [min(k), max(k), min(b), max(b)],
              norm = plt.cm.colors.SymLogNorm(1e-3)
              # norm = plt.cm.colors.LogNorm(), 
              )

fig.colorbar(h, ax = ax, label = "$ a(x, x', X) $",
             )
# ax.plot(ks, energy(ks, beta))
ax.grid(None)
ax.set_xlabel("Degree k")
ax.set_ylabel(r"$\beta = \frac{1}{T}$")

# ax.set_ylim(8, 10)
# ax.set_xlim(1, 3)

# # ax.set_yscale('symlog')
# fig.set_facecolor('w')

print()
fig.show()

print(z.min())
#+end_src


#+RESULTS:
: 23a0fb72-7b76-4ffe-9a82-522d5f48a7aa

Nodes with higher degree are less likely to change its states in face of all the
neighbors being the same state.

**** Semi-meanfield

Determining the distribution $p_{x \rightarrow x'}(x'  | X)$ is difficult due to
the dependency of $X$ on the topology of the graph structure as a whole. Namely,
for a given system, with topology $G=(V,E)$  it is non- trivial to determine the
distribution of the  neighbors. Here, we assume that the  neighbors of some node
with  degree $k$  is  binomially  distributed. Let  $L^k  \in  S$ represent  the
neighborhood of nodes with degree $k$.  We denote $p(\textrm{switch to } x')$ as
the probability of the center node switching to $x'$, and the number of nodes in
the state opposite of  the center node is distributed as  $L_i \sim Binom(x', k,
p)$.  Here $p$  can be  interpreted as  the average  magnetization $<M>$  in the
system for the Ising model; if $p=0$ corresponds to the case where all the nodes
in the neighborhood $L^k$ are the same  state as the center node. The acceptance
ratio for a node with degree $k$ then becomes:

#+name:
\begin{equation}
a^k_{x \rightarrow x'} = \exp( E_{L^k}(x) - E_{L^k}(x'))
\end{equation}

#+begin_src jupyter-python
from scipy import stats
import cmasher as cmr
import pandas as pd
def semi_mf(ks):
    ps = np.linspace(0, 1, max(ks))
    fig, axs = plt.subplots(ps.size, 2,
                            figsize = (12, 12), #  sharey = 'col',
                            sharex = 'col')
    colors = cmr.pride(np.linspace(0, 1, ps.size, endpoint = False))
    width = .85 * 1/max(ks)
    cc = cmr.pride(np.linspace(0, 1, ks.size, endpoint = 0))
    h = np.zeros(max(ks))
    norm =  lambda x: (x-x.min()) / (x.max() - x.min())
    for jdx, pi  in enumerate(ps):
        p_accept = np.zeros((ks.size))
        for idx, k in enumerate(ks):
            ax, axi = axs[jdx]
            # generate number of xprime
            xprim = np.arange(0, k)
            
            pprim = stats.binom.pmf(xprim, k, pi)
            eprim = xprim * pprim

            tmp = (k - xprim)
            p = stats.binom.pmf(tmp, k, pi)
            e  = tmp * p

            accept = (eprim / e).sum()
            accept = np.exp(pi * (e.sum() - eprim.sum()))
            p_accept[idx] = accept

            ax.bar(xprim + idx * width, e, width = width,
                   color = cc[idx], label = k)

        ax.set_xticklabels(xprim)
        ax.set_xticks(xprim + width * 1/2 * len(ks))
        c = colors[jdx]
        axi.bar(ks, height = p_accept,
            width = width, color = c, label = k)

        h[:len(x)] += x
        if jdx == 0 :
            ax.legend(loc = 'upper left', ncol = 2,
                      bbox_to_anchor = (0, 1), title = "Degree(k)")
            
        
        axi.annotate(f"p(x') = {pi:.2f}", (.8, .8), ha = 'left',
                    xycoords = 'axes fraction')
        
        # axi.set_yscale('log')
        # axi.set_yscale('symlog')
        axi.set_ylabel("a(x, x', X)")
        axi.set_xticklabels(xprim)
        # axi.set_xticks(xprim + width * 1/2 * len(ks))
        ax.grid(None)
        axi.grid(None)
    
    ax.set_xlabel("Number of neighbors with state x'")
    axi.set_xlabel("Degree(k)")
    
    maxu = fig.add_subplot(121, frameon = 0, xticks = [], yticks = [])    
    maxu.set_ylabel("binom(x', k, <M>)", labelpad = 30)
    fig.set_facecolor('w')
    fig.suptitle(r"Acceptance $x \rightarrow x'$ per degree k", fontsize = 20)
    fig.show()
ks = np.arange(1, 7)
semi_mf(ks)
#+end_src

#+RESULTS:
: 3c632180-b466-4134-b6bd-c0b47f598771
** graphs
#+begin_src jupyter-python
import matplotlib.pyplot as plt, cmasher as cmr, pandas as pd
import numpy as np, os, sys, networkx as nx, warnings
from plexsim import models
from imi import infcy
warnings.simplefilter("ignore"); plt.style.use("fivethirtyeight spooky".split())
g = nx.powerlaw_cluster_graph(100, 2, .05)
# g = nx.duplication_divergence_graph(100, .2)
fig, ax = plt.subplots()

nx.draw(g, node_size = 30, ax = ax)
ax.axis('equal')
fig.show()



degree = list(dict(g.degree()).values())
counts, bins  = np.histogram(degree, bins = 3000)
print(c, nx.is_connected(g))

fig, ax = plt.subplots()
ax.bar(bins[:-1], counts)
fig.show()


#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: [0;31m---------------------------------------------------------------------------[0m
: [0;31mNameError[0m                                 Traceback (most recent call last)
: [0;32m/tmp/ipykernel_54277/681775754.py[0m in [0;36m<module>[0;34m[0m
: [1;32m     16[0m [0mdegree[0m [0;34m=[0m [0mlist[0m[0;34m([0m[0mdict[0m[0;34m([0m[0mg[0m[0;34m.[0m[0mdegree[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m.[0m[0mvalues[0m[0;34m([0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
: [1;32m     17[0m [0mcounts[0m[0;34m,[0m [0mbins[0m  [0;34m=[0m [0mnp[0m[0;34m.[0m[0mhistogram[0m[0;34m([0m[0mdegree[0m[0;34m,[0m [0mbins[0m [0;34m=[0m [0;36m3000[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
: [0;32m---> 18[0;31m [0mprint[0m[0;34m([0m[0mc[0m[0;34m,[0m [0mnx[0m[0;34m.[0m[0mis_connected[0m[0;34m([0m[0mg[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
: [0m[1;32m     19[0m [0;34m[0m[0m
: [1;32m     20[0m [0mfig[0m[0;34m,[0m [0max[0m [0;34m=[0m [0mplt[0m[0;34m.[0m[0msubplots[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
:
: [0;31mNameError[0m: name 'c' is not defined
[[file:./.ob-jupyter/235da95611636b6ee966ca95bf778f8192090d93.png]]
:END:


** Code

** Tipping point old code
#+begin_src jupyter-python
from matplotlib import style; style.use("fivethirtyeight spooky".split())
import matplotlib.pyplot as plt, cmasher as cmr
import numpy as np, os, sys, networkx as nx, warnings
warnings.simplefilter("ignore")
from plexsim import models
from imi import infcy

g = nx.florentine_families_graph()
m = models.Potts(g, t = 1.5)
sim = infcy.Simulator(m)

snapshots = sim.snapshots(1000)
snapshots, conditional = sim.forward(snapshots, 10000).values()

bins = np.linspace(0, 1, 20)
bins = np.array([*bins[::-1]*-1, 0, *bins]) 
fig, ax = plt.subplots()
tipping = np.mean(m.agentStates)
x = np.array([np.mean(i) - tipping for i in snapshots])
ax.hist(x, bins)
ax.set_xlim(-1, 1)
fig.show()
m.sampleNodes(10).shape
#+end_src

#+RESULTS:
:RESULTS:
: 2
: checking available bytes
: setting inner dimension 100000
: Ready
: > > 5
: 0% [##############################] 100% | ETA: 00:00:00
: Total time elapsed: 00:01:36
| 10 | 15 |
[[file:./.ob-jupyter/38e6d772e9ebe8a950af5050c3aaa9eb54f4969f.png]]
:END:


#+begin_src jupyter-python
# bin everything
tipping = np.mean(m.agentStates)
df = []
for k, v in snapshots.items():
    idx = np.digitize(np.mean(k) - tipping, bins)

    bins_ = bins[idx]
    #bins_ = abs(bins_)
    c = conditional[k]
    row = dict(state = k, bin = bins_, state_count = v, conditional = c)
    df.append(row)
import pandas as pd
df = pd.DataFrame(df)

mis = {}
for x, dfi in df.groupby("bin"):
    states = np.stack(dfi.state)
    vals  = np.stack(dfi.state_count)

    snap = {tuple(s): v/sum(vals) for s, v in zip(states, vals)}

    cond = np.stack(dfi.conditional)
    cond = {tuple(s): i for s, i in zip(states, cond)}

    try:
        px, mi = infcy.mutualInformation(cond, snap)
        bin = x 
        if not np.allclose(mi.sum(), 0):
            mis[str(bin)] = mi
    except Exception as e:
        print(e)

plt.style.use('spooky')

deg = dict(nx.degree(m.graph))
rdeg = {}
adj = models.Adjacency(g)
for k, v in deg.items():
    rdeg[v] = rdeg.get(v, []) + [adj.mapping[str(k)]]
rdeg = dict(sorted(rdeg.items(), key = lambda x: x[0]))
handles = {}
from scipy.stats import sem
n = len(mis) // 2
layout = np.zeros((2, len(mis)//2), dtype = object)
for idx, mi in enumerate(mis):
    if idx >= n:
        break
    layout[1][idx] = str(mi)
    layout[0, idx] = f"{mi}c"
    
    
fig = plt.figure(constrained_layout = 1,
                 figsize = (20, 5))
ax = fig.subplot_mosaic(layout)

lc  = np.linspace(0, 1, len(rdeg))
lc  = cmr.heat(lc)
for di, axi in ax.items():
    x = di.replace('c', '')
    mi = mis[x]

    if di.endswith("c"):
        s = mi.sum(0)
        s = (s - s.min()) / (s.max() - s.min())
        nx.draw(g, pos, ax = axi, node_size = s * 340, node_color = colors)
        
        x = abs(round(float(x), 2))
        
        axi.set_title(x)
        axi.margins(.22)
        axi.axis('equal')
    else:
        for idx, (k, v) in enumerate(rdeg.items()):
            mus = mi[..., v].mean(1)
            s   = sem(mi, axis = 1) * 2
            x = np.arange(0,len(mus))
            p = axi.errorbar(x, mi[..., v].mean(1), s,
                            linewidth = 2,label = k, color = lc[idx])
            handles[k] = p
        axi.set_ylim(0, 1)
axi = fig.add_subplot(212, frameon = 0,
                      xticks = [], yticks = [])

axi.set_xlabel("Time (t)", labelpad = 25, fontsize = 20)
axi.set_ylabel("$I(s_i^{t_0 + t} ; S^t)$", labelpad = 45, fontsize = 20)
axi.legend(handles = handles.values(),
           title = "Degree (k)",
           bbox_to_anchor = (1.0, 1),
           loc = 'upper left') 
fig.subplots_adjust(hspace = .0, wspace = .3)
fig.savefig("/home/casper/orgfiles/research_plan/figures/shifter.png",
            transparent = 1)
fig.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/a7330be10cf2cc0d49e6e95623ee2813568596aa.png]]




#+begin_src jupyter-python
layout = np.zeros((1, len(mis)//2), dtype = object)
n = len(mis)//2
for idx, mi in enumerate(mis):
    if idx >= n:
        break
    layout.flat[idx] = str(mi)
    
pos = nx.kamada_kawai_layout(g)
fig = plt.figure(constrained_layout = 1,
                 figsize = (20,3))
ax = fig.subplot_mosaic(layout)
colors = cmr.pride(np.linspace(0, 1, len(g), 0))
for di, axi in ax.items():
    mi = mis[di]
    s = mi.sum(0)
    s = (s - s.min()) / (s.max() - s.min())
    nx.draw(g, pos, ax = axi, node_size = s * 340, node_color = colors)
    di = round(float(di), 2)
    axi.set_title(abs(di))
    axi.margins(.22)
    axi.axis('equal')
axi = fig.add_subplot(111, frameon = 0,
                      xticks = [], yticks = [])
#axi.set_xlabel("Time (t)", labelpad = 25, fontsize = 30)
#axi.set_ylabel("$I(s_i^{t_0 + t} ; S^t)$", labelpad = 45, fontsize = 30)

fig.subplots_adjust(hspace = .4, wspace = .2)
fig.savefig("/home/casper/orgfiles/research_plan/figures/shifter_graph.png",
            )
fig.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/31c3918d6f4725a78d916cca751fe6e40140ac96.png]]



#+begin_src jupyter-python
fig, ax = plt.subplots(figsize = (20, 2))
ax.plot(m.simulate(10000).mean(1))
fig.savefig("/home/casper/orgfiles/research_plan/figures/mags.png")
fig.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/75f04832389dd1eb2ab400050dd0af86d8fa7193.png]]







    


* Data analysis :noexport:
:PROPERTIES:
:ARCHIVE_TIME: 2022-01-19 Wed 09:14
:ARCHIVE_FILE: ~/papers/paper2/paper2.org
:ARCHIVE_CATEGORY: paper2
:END:
#+begin_src jupyter-python
import matplotlib.pyplot as plt, cmasher as cmr, pandas as pd
import numpy as np, os, sys, networkx as nx, warnings, pickle
from plexsim import models
from imi import infcy
from pathlib import Path
warnings.simplefilter("ignore"); plt.style.use("fivethirtyeight spooky".split())

fp = "/home/casper/projects/experiments/data/tipping_use"
data = []
for fn in Path(fp).iterdir():
    with open(fn, "rb") as f:
        d = pickle.load(f)
    data.append(d)
#+end_src

#+RESULTS:

#+begin_src jupyter-python
fig, ax = plt.subplots(1, len(data[0]['mis'].items()), figsize = (10, 5))
for axi, (mag, mis) in zip(ax, data[0]['mis'].items()):
    axi.plot(mis)

fig.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/89c23240235c3a6fcd9be01f9a490fca412fef63.png]]


