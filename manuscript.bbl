% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{none/global//global/global}
\preamble{%
\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi
}

  \entry{Ladyman2013}{article}{}
    \name{author}{3}{}{%
      {{hash=LJ}{%
         family={Ladyman},
         familyi={L\bibinitperiod},
         given={James},
         giveni={J\bibinitperiod},
      }}%
      {{hash=LJ}{%
         family={Lambert},
         familyi={L\bibinitperiod},
         given={James},
         giveni={J\bibinitperiod},
      }}%
      {{hash=WK}{%
         family={Wiesner},
         familyi={W\bibinitperiod},
         given={Karoline},
         giveni={K\bibinitperiod},
      }}%
    }
    \keyw{Complex system,Complexity,Information,Statistical complexity}
    \strng{namehash}{LJ+1}
    \strng{fullhash}{LJLJWK1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Complex systems research is becoming ever more important in both the
  natural and social sciences. It is commonly implied that there is such a
  thing as a complex system, different examples of which are studied across
  many disciplines. However, there is no concise definition of a complex
  system, let alone a definition on which all scientists agree. We review
  various attempts to characterize a complex system, and consider a core set of
  features that are widely associated with complex systems in the literature
  and by those in the field. We argue that some of these features are neither
  necessary nor sufficient for complexity, and that some of them are too vague
  or confused to be of any analytical use. In order to bring mathematical
  rigour to the issue we then review some standard measures of complexity from
  the scientific literature, and offer a taxonomy for them, before arguing that
  the one that best captures the qualitative notion of the order produced by
  complex systems is that of the Statistical Complexity. Finally, we offer our
  own list of necessary conditions as a characterization of complexity. These
  conditions are qualitative and may not be jointly sufficient for complexity.
  We close with some suggestions for future work. © 2012 Springer Science +
  Business Media B.V.%
    }
    \verb{doi}
    \verb 10.1007/s13194-012-0056-8
    \endverb
    \field{issn}{1879-4912}
    \field{number}{1}
    \field{pages}{33\bibrangedash 67}
    \field{title}{What Is a Complex System?}
    \field{volume}{3}
    \verb{file}
    \verb /home/casper/Zotero/storage/NW9HNB5M/Ladyman, Lambert, Wiesner - 2013
    \verb  - What is a complex system(2).pdf
    \endverb
    \field{journaltitle}{European Journal for Philosophy of Science}
    \field{day}{19}
    \field{month}{01}
    \field{year}{2013}
  \endentry

  \entry{vanNes2016}{article}{useprefix}
    \name{author}{7}{}{%
      {{hash=vNEH}{%
         prefix={van},
         prefixi={v\bibinitperiod},
         family={Nes},
         familyi={N\bibinitperiod},
         given={Egbert\bibnamedelima H.},
         giveni={E\bibinitperiod\bibinitdelim H\bibinitperiod},
      }}%
      {{hash=ABM}{%
         family={Arani},
         familyi={A\bibinitperiod},
         given={Babak\bibnamedelima M.S.},
         giveni={B\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
      {{hash=SA}{%
         family={Staal},
         familyi={S\bibinitperiod},
         given={Arie},
         giveni={A\bibinitperiod},
      }}%
      {{hash=vdBB}{%
         prefix={van\bibnamedelima der},
         prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod},
         family={Bolt},
         familyi={B\bibinitperiod},
         given={Bregje},
         giveni={B\bibinitperiod},
      }}%
      {{hash=FBM}{%
         family={Flores},
         familyi={F\bibinitperiod},
         given={Bernardo\bibnamedelima M.},
         giveni={B\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
      {{hash=BS}{%
         family={Bathiany},
         familyi={B\bibinitperiod},
         given={Sebastian},
         giveni={S\bibinitperiod},
      }}%
      {{hash=SM}{%
         family={Scheffer},
         familyi={S\bibinitperiod},
         given={Marten},
         giveni={M\bibinitperiod},
      }}%
    }
    \strng{namehash}{vNEH+1}
    \strng{fullhash}{vNEHABMSAvdBBFBMBSSM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \verb{doi}
    \verb 10.1016/j.tree.2016.09.011
    \endverb
    \field{issn}{01695347}
    \field{number}{12}
    \field{pages}{902\bibrangedash 904}
    \field{shortjournal}{Trends in Ecology \& Evolution}
    \field{title}{What {{Do You Mean}}, ‘{{Tipping Point}}’?}
    \field{volume}{31}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/IFH4VFTI/van Nes et al. - 2016 - What Do
    \verb You Mean, ‘Tipping Point’.pdf
    \endverb
    \field{journaltitle}{Trends in Ecology \& Evolution}
    \field{month}{12}
    \field{year}{2016}
  \endentry

  \entry{Fries2015}{article}{}
    \name{author}{1}{}{%
      {{hash=FP}{%
         family={Fries},
         familyi={F\bibinitperiod},
         given={Pascal},
         giveni={P\bibinitperiod},
      }}%
    }
    \strng{namehash}{FP1}
    \strng{fullhash}{FP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \verb{doi}
    \verb 10.1016/j.neuron.2015.09.034
    \endverb
    \field{issn}{08966273}
    \field{number}{1}
    \field{pages}{220\bibrangedash 235}
    \field{shortjournal}{Neuron}
    \field{shorttitle}{Rhythms for {{Cognition}}}
    \field{title}{Rhythms for {{Cognition}}: {{Communication}} through
  {{Coherence}}}
    \field{volume}{88}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/6WTTIY9L/Fries_2015_Rhythms for Cognition
    \verb .pdf
    \endverb
    \field{journaltitle}{Neuron}
    \field{month}{10}
    \field{year}{2015}
  \endentry

  \entry{Kandel2000}{book}{}
    \name{author}{3}{}{%
      {{hash=KER}{%
         family={Kandel},
         familyi={K\bibinitperiod},
         given={Eric\bibnamedelima R},
         giveni={E\bibinitperiod\bibinitdelim R\bibinitperiod},
      }}%
      {{hash=SJH}{%
         family={Schwartz},
         familyi={S\bibinitperiod},
         given={J\bibnamedelima H},
         giveni={J\bibinitperiod\bibinitdelim H\bibinitperiod},
      }}%
      {{hash=JTM}{%
         family={Jessell},
         familyi={J\bibinitperiod},
         given={Thomas\bibnamedelima M},
         giveni={T\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{McGraw-Hill Medical}}%
    }
    \keyw{neuroscience}
    \strng{namehash}{KER+1}
    \strng{fullhash}{KERSJHJTM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Now in resplendent color, the new edition continues to define the latest in
  the scientific understanding of the brain, the nervous system, and human
  behavior. Each chapter is thoroughly revised and includes the impact of
  molecular biology in the mechanisms underlying developmental processes and in
  the pathogenesis of disease. Important features to this edition include a new
  chapter - Genes and Behavior; a complete updating of development of the
  nervous system; the genetic basis of neurological and psychiatric disease;
  cognitive neuroscience of perception, planning, action, motivation and
  memory; ion channel mechanisms; and much more.%
    }
    \field{edition}{4}
    \field{isbn}{0-07-112000-9}
    \field{title}{Principles of {{Neural Science}}}
    \verb{url}
    \verb http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20%5C&path
    \verb =ASIN/0071120009
    \endverb
    \field{month}{07}
    \field{year}{2000}
  \endentry

  \entry{Galam2020}{article}{}
    \name{author}{2}{}{%
      {{hash=GS}{%
         family={Galam},
         familyi={G\bibinitperiod},
         given={Serge},
         giveni={S\bibinitperiod},
      }}%
      {{hash=CT}{%
         family={Cheon},
         familyi={C\bibinitperiod},
         given={Taksu},
         giveni={T\bibinitperiod},
      }}%
    }
    \keyw{Condensed Matter - Statistical Mechanics,Nonlinear Sciences -
  Adaptation and Self-Organizing Systems,Physics - Physics and Society}
    \strng{namehash}{GSCT1}
    \strng{fullhash}{GSCT1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{abstract}{%
    A universal formula is shown to predict the dynamics of public opinion
  including eventual sudden and unexpected outbreaks of minority opinions
  within a generic parameter space of five dimensions. The formula is obtained
  combining and extending several components of Galam model of opinion
  dynamics, otherwise treated separately, into one single update equation,
  which then deploys in a social space of five dimensions. Four dimensions
  account for a rich diversity of individual traits within a heterogeneous
  population, including differentiated stubbornness, contrarianism, and
  embedded prejudices. The fifth dimension is the size for the discussing
  update groups. Having one single formula allows exploring the complete
  geometry of the underlying landscape of opinion dynamics. Attractors and
  tipping points, which shape the topology of the different possible dynamics
  flows, are unveiled. Driven by repeated discussions among small groups of
  people during a social or political public campaign, the phenomenon of
  minority spreading and parallel majority collapse are thus revealed ahead of
  their occurrence. Accordingly, within the opinion landscape, unexpected and
  sudden events like Brexit and Trump victories become visible within a
  forecast time horizon making them predictable. Despite the accidental nature
  of the landscape, evaluating the parameter values for a specific case allows
  to single out which basin of attraction is going to drive the associate
  dynamics and thus a prediction of the outcome becomes feasible. The model may
  apply to a large spectrum of social situations including voting outcomes,
  market shares and societal trends, allowing to envision novel winning
  strategies in competing environments.%
    }
    \verb{doi}
    \verb 10.3389/fphy.2020.566580
    \endverb
    \verb{eprint}
    \verb 1901.09622
    \endverb
    \field{issn}{2296-424X}
    \field{pages}{566580}
    \field{shortjournal}{Front. Phys.}
    \field{shorttitle}{Tipping Points in Opinion Dynamics}
    \field{title}{Tipping Points in Opinion Dynamics: A Universal Formula in
  Five Dimensions}
    \field{volume}{8}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/BKBLWWGI/Galam and Cheon - 2020 - Tipping
    \verb  points in opinion dynamics a universal fo.pdf
    \endverb
    \field{journaltitle}{Frontiers in Physics}
    \field{eprinttype}{arxiv}
    \field{eprintclass}{cond-mat, physics:nlin, physics:physics}
    \field{day}{10}
    \field{month}{11}
    \field{year}{2020}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{1986}{article}{}
    \field{labeltitlesource}{title}
    \field{title}{© 1986 {{Nature Publishing Group}}}
    \field{year}{1986}
  \endentry

  \entry{Wunderling2021}{article}{}
    \name{author}{4}{}{%
      {{hash=WN}{%
         family={Wunderling},
         familyi={W\bibinitperiod},
         given={Nico},
         giveni={N\bibinitperiod},
      }}%
      {{hash=DJF}{%
         family={Donges},
         familyi={D\bibinitperiod},
         given={Jonathan\bibnamedelima F.},
         giveni={J\bibinitperiod\bibinitdelim F\bibinitperiod},
      }}%
      {{hash=KJ}{%
         family={Kurths},
         familyi={K\bibinitperiod},
         given={Jürgen},
         giveni={J\bibinitperiod},
      }}%
      {{hash=WR}{%
         family={Winkelmann},
         familyi={W\bibinitperiod},
         given={Ricarda},
         giveni={R\bibinitperiod},
      }}%
    }
    \strng{namehash}{WN+1}
    \strng{fullhash}{WNDJFKJWR1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    With progressing global warming, there is an increased risk that one or
  several tipping elements in the climate system might cross a critical
  threshold, resulting in severe consequences for the global climate,
  ecosystems and human societies. While the underlying processes are fairly
  well-understood, it is unclear how their interactions might impact the
  overall stability of the Earth’s climate system. As of yet, this cannot be
  fully analysed with state-of-the-art Earth system models due to computational
  constraints as well as some missing and uncertain process representations of
  certain tipping elements. Here, we explicitly study the effects of known
  physical interactions among the Greenland and West Antarctic ice sheets, the
  Atlantic Meridional Overturning Circulation (AMOC) and the Amazon rainforest
  using a conceptual network approach. We analyse the risk of domino effects
  being triggered by each of the individual tipping elements under global
  warming in equilibrium experiments. In these experiments, we propagate the
  uncertainties in critical temperature thresholds, interaction strengths and
  interaction structure via large ensembles of simulations in a Monte Carlo
  approach. Overall, we find that the interactions tend to destabilise the
  network of tipping elements. Furthermore, our analysis reveals the
  qualitative role of each of the four tipping elements within the network,
  showing that the polar ice sheets on Greenland and West Antarctica are
  oftentimes the initiators of tipping cascades, while the AMOC acts as a
  mediator transmitting cascades. This indicates that the ice sheets, which are
  already at risk of transgressing their temperature thresholds within the
  Paris range of 1.5 to 2 ◦C, are of particular importance for the stability
  of the climate system as a whole.%
    }
    \verb{doi}
    \verb 10.5194/esd-12-601-2021
    \endverb
    \field{issn}{2190-4987}
    \field{number}{2}
    \field{pages}{601\bibrangedash 619}
    \field{shortjournal}{Earth Syst. Dynam.}
    \field{title}{Interacting Tipping Elements Increase Risk of Climate Domino
  Effects under Global Warming}
    \field{volume}{12}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/ABNBRVL5/Wunderling et al. - 2021 - Inter
    \verb acting tipping elements increase risk of clim.pdf
    \endverb
    \field{journaltitle}{Earth System Dynamics}
    \field{day}{03}
    \field{month}{06}
    \field{year}{2021}
  \endentry

  \entry{Beggs2012}{article}{}
    \name{author}{2}{}{%
      {{hash=BJM}{%
         family={Beggs},
         familyi={B\bibinitperiod},
         given={John\bibnamedelima M.},
         giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
      {{hash=TN}{%
         family={Timme},
         familyi={T\bibinitperiod},
         given={Nicholas},
         giveni={N\bibinitperiod},
      }}%
    }
    \strng{namehash}{BJMTN1}
    \strng{fullhash}{BJMTN1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Relatively recent work has reported that networks of neurons can produce
  avalanches of activity whose sizes follow a power law distribution. This
  suggests that these networks may be operating near a critical point, poised
  between a phase where activity rapidly dies out and a phase where activity is
  amplified over time. The hypothesis that the electrical activity of neural
  networks in the brain is critical is potentially important, as many
  simulations suggest that information processing functions would be optimized
  at the critical point. This hypothesis, however, is still controversial. Here
  we will explain the concept of criticality and review the substantial
  objections to the criticality hypothesis raised by skeptics. Points and
  counter points are presented in dialog form.%
    }
    \verb{doi}
    \verb 10.3389/fphys.2012.00163
    \endverb
    \field{issn}{1664-042X}
    \field{shortjournal}{Front. Physio.}
    \field{title}{Being {{Critical}} of {{Criticality}} in the {{Brain}}}
    \field{volume}{3}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/TTQKKY69/Beggs and Timme - 2012 - Being C
    \verb ritical of Criticality in the Brain.pdf
    \endverb
    \field{journaltitle}{Frontiers in Physiology}
    \field{year}{2012}
  \endentry

  \entry{Mitchell1993}{unpublished}{}
    \name{author}{3}{}{%
      {{hash=MM}{%
         family={Mitchell},
         familyi={M\bibinitperiod},
         given={Melanie},
         giveni={M\bibinitperiod},
      }}%
      {{hash=HP}{%
         family={Hraber},
         familyi={H\bibinitperiod},
         given={Peter},
         giveni={P\bibinitperiod},
      }}%
      {{hash=CJP}{%
         family={Crutchfield},
         familyi={C\bibinitperiod},
         given={James\bibnamedelima P.},
         giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
      }}%
    }
    \strng{namehash}{MM+1}
    \strng{fullhash}{MMHPCJP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    We present results from an experiment similar to one performed by Packard
  (1988), in which a genetic algorithm is used to evolve cellular automata (CA)
  to perform a particular computational task. Packard examined the frequency of
  evolved CA rules as a function of Langton's lambda parameter (Langton, 1990),
  and interpreted the results of his experiment as giving evidence for the
  following two hypotheses: (1) CA rules able to perform complex computations
  are most likely to be found near ``critical'' lambda values, which have been
  claimed to correlate with a phase transition between ordered and chaotic
  behavioral regimes for CA; (2) When CA rules are evolved to perform a complex
  computation, evolution will tend to select rules with lambda values close to
  the critical values. Our experiment produced very different results, and we
  suggest that the interpretation of the original results is not correct. We
  also review and discuss issues related to lambda, dynamical-behavior classes,
  and computation in CA. The main constructive results of our study are
  identifying the emergence and competition of computational strategies and
  analyzing the central role of symmetries in an evolutionary system. In
  particular, we demonstrate how symmetry breaking can impede the evolution
  toward higher computational capability.%
    }
    \verb{eprint}
    \verb adap-org/9303003
    \endverb
    \field{pages}{1\bibrangedash 38}
    \field{title}{Revisiting the {{Edge}} of {{Chaos}}: {{Evolving Cellular
  Automata}} to {{Perform Computations}}}
    \verb{url}
    \verb http://arxiv.org/abs/adap-org/9303003
    \endverb
    \field{eprinttype}{arxiv}
    \field{year}{1993}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Mitchella}{article}{}
    \name{author}{3}{}{%
      {{hash=MM}{%
         family={Mitchell},
         familyi={M\bibinitperiod},
         given={Melanie},
         giveni={M\bibinitperiod},
      }}%
      {{hash=CJP}{%
         family={Crutchfield},
         familyi={C\bibinitperiod},
         given={James\bibnamedelima P},
         giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
      }}%
      {{hash=HP}{%
         family={Hraber},
         familyi={H\bibinitperiod},
         given={Peter},
         giveni={P\bibinitperiod},
      }}%
    }
    \strng{namehash}{MM+1}
    \strng{fullhash}{MMCJPHP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    In this paper we review previous work and present new work concerning the
  relationship between dynamical systems theory and computation. In particular,
  we review work by Langton 21] and Packard 29] on the relationship between
  dynamical behavior and computational capability in cellular automata (CAs).
  We present results from an experiment similar to the one described by Packard
  29], which was cited as evidence for the hypothesis that rules capable of
  performing complex computations are most likely to be found at a phase
  transition between ordered and chaotic behavioral regimes for CAs (the
  \textbackslash edge of chaos"). Our experiment produced very di erent results
  from the original experiment, and we suggest that the interpretation of the
  original results is not correct. We conclude by discussing general issues
  related to dynamics, computation, and the \textbackslash edge of chaos" in
  cellular automata.%
    }
    \field{pages}{17}
    \field{title}{Dynamics, {{Computation}}, and the “{{Edge}} of
  {{Chaos}}”: {{A Re- Examination}}}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/BLXWJ8A7/Mitchell et al. - Dynamics, Comp
    \verb utation, and the “Edge of Chaos” A .pdf
    \endverb
  \endentry

  \entry{Forgoston2018a}{article}{}
    \name{author}{2}{}{%
      {{hash=FE}{%
         family={Forgoston},
         familyi={F\bibinitperiod},
         given={Eric},
         giveni={E\bibinitperiod},
      }}%
      {{hash=MRO}{%
         family={Moore},
         familyi={M\bibinitperiod},
         given={Richard\bibnamedelima O.},
         giveni={R\bibinitperiod\bibinitdelim O\bibinitperiod},
      }}%
    }
    \strng{namehash}{FEMRO1}
    \strng{fullhash}{FEMRO1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Noise plays a fundamental role in a wide variety of physical and biological
  dynamical systems. It can arise from an external forcing or due to random
  dynamics internal to the system. It is well established that even weak noise
  can result in large behavioral changes such as transitions between or escapes
  from quasi-stable states. These transitions can correspond to critical events
  such as failures or extinctions that make them essential phenomena to
  understand and quantify, despite the fact that their occurrence is rare. This
  article will provide an overview of the theory underlying the dynamics of
  rare events for stochastic models along with some example applications.%
    }
    \verb{doi}
    \verb 10.1137/17M1142028
    \endverb
    \field{issn}{0036-1445, 1095-7200}
    \field{number}{4}
    \field{pages}{969\bibrangedash 1009}
    \field{shortjournal}{SIAM Rev.}
    \field{title}{A {{Primer}} on {{Noise-Induced Transitions}} in {{Applied
  Dynamical Systems}}}
    \field{volume}{60}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/VL765RFM/Forgoston and Moore - 2018 - A P
    \verb rimer on Noise-Induced Transitions in Applied D.pdf
    \endverb
    \field{journaltitle}{SIAM Review}
    \field{month}{01}
    \field{year}{2018}
  \endentry

  \entry{Czaplicka2013}{article}{}
    \name{author}{3}{}{%
      {{hash=CA}{%
         family={Czaplicka},
         familyi={C\bibinitperiod},
         given={Agnieszka},
         giveni={A\bibinitperiod},
      }}%
      {{hash=HJA}{%
         family={Holyst},
         familyi={H\bibinitperiod},
         given={Janusz\bibnamedelima A.},
         giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod},
      }}%
      {{hash=SPM}{%
         family={Sloot},
         familyi={S\bibinitperiod},
         given={Peter\bibnamedelima M.A.},
         giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \keyw{statistical physics}
    \strng{namehash}{CA+2}
    \strng{fullhash}{CAHJASPM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    We study the influence of noise on information transmission in the form of
  packages shipped between nodes of hierarchical networks. Numerical
  simulations are performed for artificial tree networks, scale-free
  Ravasz-Barabási networks as well for a real network formed by email
  addresses of former Enron employees. Two types of noise are considered. One
  is related to packet dynamics and is responsible for a random part of packets
  paths. The second one originates from random changes in initial network
  topology. We find that the information transfer can be enhanced by the noise.
  The system possesses optimal performance when both kinds of noise are tuned
  to specific values, this corresponds to the Stochastic Resonance phenomenon.
  There is a non-trivial synergy present for both noisy components. We found
  also that hierarchical networks built of nodes of various degrees are more
  efficient in information transfer than trees with a fixed branching factor.%
    }
    \verb{doi}
    \verb 10.1038/srep01223
    \endverb
    \field{issn}{20452322}
    \field{title}{Noise Enhances Information Transfer in Hierarchical Networks}
    \field{volume}{3}
    \field{journaltitle}{Scientific Reports}
    \field{year}{2013}
  \endentry

  \entry{Nicolis2016}{article}{}
    \name{author}{2}{}{%
      {{hash=NG}{%
         family={Nicolis},
         familyi={N\bibinitperiod},
         given={Grégoire},
         giveni={G\bibinitperiod},
      }}%
      {{hash=NC}{%
         family={Nicolis},
         familyi={N\bibinitperiod},
         given={Catherine},
         giveni={C\bibinitperiod},
      }}%
    }
    \strng{namehash}{NGNC1}
    \strng{fullhash}{NGNC1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    A class of complex self-organizing systems subjected to fluctuations of
  environmental or intrinsic origin and to nonequilibrium constraints in the
  form of an external periodic forcing is analyzed from the standpoint of
  information theory. Conditions under which the response of information
  entropy and related quantities to the nonequilibrium constraint can be
  optimized via a stochastic resonance-type mechanism are identified, and the
  role of key parameters is assessed.%
    }
    \verb{doi}
    \verb 10.3390/e18050172
    \endverb
    \field{issn}{1099-4300}
    \field{number}{5}
    \field{pages}{172}
    \field{shortjournal}{Entropy}
    \field{title}{Stochastic {{Resonance}}, {{Self-Organization}} and
  {{Information Dynamics}} in {{Multistable Systems}}}
    \field{volume}{18}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/IC42LUGS/Nicolis and Nicolis - 2016 - Sto
    \verb chastic Resonance, Self-Organization and Inform.pdf
    \endverb
    \field{journaltitle}{Entropy}
    \field{day}{04}
    \field{month}{05}
    \field{year}{2016}
  \endentry

  \entry{Hopfield1982b}{article}{}
    \name{author}{1}{}{%
      {{hash=HJJ}{%
         family={Hopfield},
         familyi={H\bibinitperiod},
         given={J\bibnamedelima J},
         giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod},
      }}%
    }
  \keyw{Animals,Computers,Mathematics,Memory,Models,Neurological,Neurons,Neurons:
  physiology}
    \strng{namehash}{HJJ1}
    \strng{fullhash}{HJJ1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Computational properties of use of biological organisms or to the
  construction of computers can emerge as collective properties of systems
  having a large number of simple equivalent components (or neurons). The
  physical meaning of content-addressable memory is described by an appropriate
  phase space flow of the state of a system. A model of such a system is given,
  based on aspects of neurobiology but readily adapted to integrated circuits.
  The collective properties of this model produce a content-addressable memory
  which correctly yields an entire memory from any subpart of sufficient size.
  The algorithm for the time evolution of the state of the system is based on
  asynchronous parallel processing. Additional emergent collective properties
  include some capacity for generalization, familiarity recognition,
  categorization, error correction, and time sequence retention. The collective
  properties are only weakly sensitive to details of the modeling or the
  failure of individual devices.%
    }
    \verb{eprint}
    \verb 6953413
    \endverb
    \field{issn}{0027-8424}
    \field{number}{8}
    \field{pages}{2554\bibrangedash 8}
    \field{title}{Neural Networks and Physical Systems with Emergent Collective
  Computational Abilities.}
    \field{volume}{79}
    \field{journaltitle}{Proceedings of the National Academy of Sciences of the
  United States of America}
    \field{eprinttype}{pmid}
    \field{month}{05}
    \field{year}{1982}
  \endentry

  \entry{Glauber1963}{article}{}
    \name{author}{1}{}{%
      {{hash=GRJ}{%
         family={Glauber},
         familyi={G\bibinitperiod},
         given={Roy\bibnamedelima J.},
         giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod},
      }}%
    }
    \strng{namehash}{GRJ1}
    \strng{fullhash}{GRJ1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    The individual spins of the Ising model are assumed to interact with an
  external agency (e.g., a heat reservoir) which causes them to change their
  states randomly with time. Coupling between the spins is introduced through
  the assumption that the transition probabilities for any one spin depend on
  the values of the neighboring spins. This dependence is determined, in part,
  by the detailed balancing condition obeyed by the equilibrium state of the
  model. The Markoff process which describes the spin functions is analyzed in
  detail for the case of a closed N‐member chain. The expectation values of
  the individual spins and of the products of pairs of spins, each of the pair
  evaluated at a different time, are found explicitly. The influence of a
  uniform, time‐varying magnetic field upon the model is discussed, and the
  frequency‐dependent magnetic susceptibility is found in the weak‐field
  limit. Some fluctuation‐dissipation theorems are derived which relate the
  susceptibility to the Fourier transform of the time‐dependent correlation
  function of the magnetization at equilibrium.%
    }
    \verb{doi}
    \verb 10.1063/1.1703954
    \endverb
    \field{isbn}{0022-2488}
    \field{issn}{00222488}
    \field{number}{2}
    \field{pages}{294\bibrangedash 307}
    \field{title}{Time-Dependent Statistics of the {{Ising}} Model}
    \field{volume}{4}
    \verb{file}
    \verb /home/casper/Zotero/storage/VPS5IRAR/Glauber - 1963 - Time-dependent
    \verb statistics of the Ising model(2).pdf
    \endverb
    \field{journaltitle}{Journal of Mathematical Physics}
    \field{year}{1963}
  \endentry

  \entry{DOrsogna2015a}{article}{}
    \name{author}{2}{}{%
      {{hash=DMR}{%
         family={D'Orsogna},
         familyi={D\bibinitperiod},
         given={Maria\bibnamedelima R.},
         giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod},
      }}%
      {{hash=PM}{%
         family={Perc},
         familyi={P\bibinitperiod},
         given={Matjaž},
         giveni={M\bibinitperiod},
      }}%
    }
    \strng{namehash}{DMRPM1}
    \strng{fullhash}{DMRPM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{abstract}{%
    Containing the spread of crime in urban societies remains a major
  challenge. Empirical evidence suggests that, if left unchecked, crimes may be
  recurrent and proliferate. On the other hand, eradicating a culture of crime
  may be difficult, especially under extreme social circumstances that impair
  the creation of a shared sense of social responsibility. Although our
  understanding of the mechanisms that drive the emergence and diffusion of
  crime is still incomplete, recent research highlights applied mathematics and
  methods of statistical physics as valuable theoretical resources that may
  help us better understand criminal activity. We review different approaches
  aimed at modeling and improving our understanding of crime, focusing on the
  nucleation of crime hotspots using partial differential equations,
  self-exciting point process and agent-based modeling, adversarial
  evolutionary games, and the network science behind the formation of gangs and
  large-scale organized crime. We emphasize that statistical physics of crime
  can relevantly inform the design of successful crime prevention strategies,
  as well as improve the accuracy of expectations about how different policing
  interventions should impact malicious human activity that deviates from
  social norms. We also outline possible directions for future research,
  related to the effects of social and coevolving networks and to the
  hierarchical growth of criminal structures due to self-organization.%
    }
    \verb{doi}
    \verb 10.1016/j.plrev.2014.11.001
    \endverb
    \field{issn}{15710645}
    \field{pages}{1\bibrangedash 21}
    \field{shortjournal}{Physics of Life Reviews}
    \field{shorttitle}{Statistical Physics of Crime}
    \field{title}{Statistical Physics of Crime: {{A}} Review}
    \field{volume}{12}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/RHNXHZCZ/D'Orsogna and Perc - 2015 - Stat
    \verb istical physics of crime A review.pdf
    \endverb
    \field{journaltitle}{Physics of Life Reviews}
    \field{month}{03}
    \field{year}{2015}
  \endentry

  \entry{Harush2017a}{article}{}
    \name{author}{2}{}{%
      {{hash=HU}{%
         family={Harush},
         familyi={H\bibinitperiod},
         given={Uzi},
         giveni={U\bibinitperiod},
      }}%
      {{hash=BB}{%
         family={Barzel},
         familyi={B\bibinitperiod},
         given={Baruch},
         giveni={B\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{Springer US}}%
    }
    \strng{namehash}{HUBB1}
    \strng{fullhash}{HUBB1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Although networks are extensively used to visualize information flow in
  biological, social and technological systems, translating topology into
  dynamic flow continues to challenge us, as similar networks exhibit
  fundamentally different flow patterns, driven by different interaction
  mechanisms. To uncover a network’s actual flow patterns, here we use a
  perturbative formalism, analytically tracking the contribution of all
  nodes/paths to the flow of information, exposing the rules that link
  structure and dynamic information flow for a broad range of nonlinear
  systems. We find that the diversity of flow patterns can be mapped into a
  single universal function, characterizing the interplay between the
  system’s topology and its dynamics, ultimately allowing us to identify the
  network’s main arteries of information flow. Counter-intuitively, our
  formalism predicts a family of frequently encountered dynamics where the flow
  of information avoids the hubs, favoring the network’s peripheral pathways,
  a striking disparity between structure and dynamics.%
    }
    \verb{doi}
    \verb 10.1038/s41467-017-01916-3
    \endverb
    \field{issn}{20411723}
    \field{number}{1}
    \field{pages}{1\bibrangedash 11}
    \field{title}{Dynamic Patterns of Information Flow in Complex Networks}
    \field{volume}{8}
    \verb{file}
    \verb /home/casper/Zotero/storage/PFZFNYYG/Harush, Barzel - 2017 - Dynafmic
    \verb  patterns of information flow in complex networks(2).pdf
    \endverb
    \field{journaltitle}{Nature Communications}
    \field{year}{2017}
  \endentry

  \entry{Gao2016}{article}{}
    \name{author}{3}{}{%
      {{hash=GJ}{%
         family={Gao},
         familyi={G\bibinitperiod},
         given={Jianxi},
         giveni={J\bibinitperiod},
      }}%
      {{hash=BB}{%
         family={Barzel},
         familyi={B\bibinitperiod},
         given={Baruch},
         giveni={B\bibinitperiod},
      }}%
      {{hash=BAL}{%
         family={Barabási},
         familyi={B\bibinitperiod},
         given={Albert-László},
         giveni={A\bibinithyphendelim L\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{Nature Publishing Group}}%
    }
    \strng{namehash}{GJ+1}
    \strng{fullhash}{GJBBBAL1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    We have shown previously that the AKT2 pathway is essential for cell
  survival and important in malignant transformation. In this study, we
  demonstrate elevated kinase levels of AKT2 and phosphatidylinositol-3-OH
  kinase (PI3K) in 32 of 80 primary breast carcinomas. The majority of the
  cases with the activation are estrogen receptor alpha (ERalpha) positive,
  which prompted us to examine whether AKT2 regulates ERalpha activity. We
  found that constitutively activated AKT2 or AKT2 activated by epidermal
  growth factor or insulin-like growth factor-1 promotes the transcriptional
  activity of ERalpha. This effect occurred in the absence or presence of
  estrogen. Activated AKT2 phosphorylates ERalpha in vitro and in vivo, but it
  does not phosphorylate a mutant ERalpha in which ser-167 was replaced by Ala.
  The PI3K inhibitor, wortmannin, abolishes both the phosphorylation and
  transcriptional activity of ERalpha induced by AKT2. However, AKT2-induced
  ERalpha activity was not inhibited by tamoxifen but was completely abolished
  by ICI 164,384, implicating that AKT2-activated ERalpha contributes to
  tamoxifen resistance. Moreover, we found that ERalpha binds to the p85alpha
  regulatory subunit of PI3K in the absence or presence of estradiol in
  epithelial cells and subsequently activates PI3K/AKT2, suggesting ERalpha
  regulation of PI3K/AKT2 through a nontranscriptional and ligand-independent
  mechanism. These data indicate that regulation between the ERalpha and
  PI3K/AKT2 pathway (ERalpha-PI3K/AKT2-ERalpha) may play an important role in
  pathogenesis of human breast cancer and could contribute to
  ligand-independent breast cancer cell growth.%
    }
    \verb{doi}
    \verb 10.1038/nature18019
    \endverb
    \verb{eprint}
    \verb 11507039
    \endverb
    \field{isbn}{0008-5472 (Print)\$\textbackslash\$r0008-5472 (Linking)}
    \field{issn}{0028-0836}
    \field{number}{7615}
    \field{pages}{238\bibrangedash 238}
    \field{title}{Universal Resilience Patterns in Complex Networks}
    \field{volume}{536}
    \verb{file}
    \verb /home/casper/Zotero/storage/Z8RN3VSI/Gao, Barzel, Barabási - 2016 -
    \verb Universal resilience patterns in complex networks(2).pdf
    \endverb
    \field{journaltitle}{Nature}
    \field{eprinttype}{pmid}
    \field{year}{2016}
  \endentry

  \entry{Wunderling2020}{article}{}
    \name{author}{7}{}{%
      {{hash=WN}{%
         family={Wunderling},
         familyi={W\bibinitperiod},
         given={Nico},
         giveni={N\bibinitperiod},
      }}%
      {{hash=SB}{%
         family={Stumpf},
         familyi={S\bibinitperiod},
         given={Benedikt},
         giveni={B\bibinitperiod},
      }}%
      {{hash=KJ}{%
         family={Krönke},
         familyi={K\bibinitperiod},
         given={Jonathan},
         giveni={J\bibinitperiod},
      }}%
      {{hash=SA}{%
         family={Staal},
         familyi={S\bibinitperiod},
         given={Arie},
         giveni={A\bibinitperiod},
      }}%
      {{hash=TOA}{%
         family={Tuinenburg},
         familyi={T\bibinitperiod},
         given={Obbe\bibnamedelima A.},
         giveni={O\bibinitperiod\bibinitdelim A\bibinitperiod},
      }}%
      {{hash=WR}{%
         family={Winkelmann},
         familyi={W\bibinitperiod},
         given={Ricarda},
         giveni={R\bibinitperiod},
      }}%
      {{hash=DJF}{%
         family={Donges},
         familyi={D\bibinitperiod},
         given={Jonathan\bibnamedelima F.},
         giveni={J\bibinitperiod\bibinitdelim F\bibinitperiod},
      }}%
    }
    \strng{namehash}{WN+1}
    \strng{fullhash}{WNSBKJSATOAWRDJF1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{abstract}{%
    In this study, we investigate how specific micro-interaction structures
  (motifs) affect the occurrence of tipping cascades on networks of stylized
  tipping elements. We compare the properties of cascades in Erdo˝s–Rényi
  networks and an exemplary moisture recycling network of the Amazon
  rainforest. Within these networks, decisive small-scale motifs are the feed
  forward loop, the secondary feed forward loop, the zero loop, and the
  neighboring loop. Of all motifs, the feed forward loop motif stands out in
  tipping cascades since it decreases the critical coupling strength necessary
  to initiate a cascade more than the other motifs. We find that for this
  motif, the reduction of critical coupling strength is 11\% less than the
  critical coupling of a pair of tipping elements. For highly connected
  networks, our analysis reveals that coupled feed forward loops coincide with
  a strong 90\% decrease in the critical coupling strength. For the highly
  clustered moisture recycling network in the Amazon, we observe regions of a
  very high motif occurrence for each of the four investigated motifs,
  suggesting that these regions are more vulnerable. The occurrence of motifs
  is found to be one order of magnitude higher than in a random
  Erdo˝s–Rényi network. This emphasizes the importance of local interaction
  structures for the emergence of global cascades and the stability of the
  network as a whole.%
    }
    \verb{doi}
    \verb 10.1063/1.5142827
    \endverb
    \field{issn}{1054-1500, 1089-7682}
    \field{number}{4}
    \field{pages}{043129}
    \field{shortjournal}{Chaos}
    \field{shorttitle}{How Motifs Condition Critical Thresholds for Tipping
  Cascades in Complex Networks}
    \field{title}{How Motifs Condition Critical Thresholds for Tipping Cascades
  in Complex Networks: {{Linking}} Micro- to Macro-Scales}
    \field{volume}{30}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/NVIWHN5B/Wunderling et al. - 2020 - How m
    \verb otifs condition critical thresholds for tippi.pdf
    \endverb
    \field{journaltitle}{Chaos: An Interdisciplinary Journal of Nonlinear
  Science}
    \field{month}{04}
    \field{year}{2020}
  \endentry

  \entry{Cover2005}{book}{}
    \name{author}{2}{}{%
      {{hash=CTM}{%
         family={Cover},
         familyi={C\bibinitperiod},
         given={Thomas\bibnamedelima M.},
         giveni={T\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
      {{hash=TJA}{%
         family={Thomas},
         familyi={T\bibinitperiod},
         given={Joy\bibnamedelima A.},
         giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod},
      }}%
    }
    \strng{namehash}{CTMTJA1}
    \strng{fullhash}{CTMTJA1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Following a brief introduction and overview, early chapters cover the basic
  algebraic relationships of entropy, relative entropy and mutual information,
  AEP, entropy rates of stochastics processes and data compression, duality of
  data compression and the growth rate of wealth. Later chapters explore
  Kolmogorov complexity, channel capacity, differential entropy, the capacity
  of the fundamental Gaussian channel, the relationship between information
  theory and statistics, rate distortion and network information theories. The
  final two chapters examine the stock market and inequalities in information
  theory. In many cases the authors actually describe the properties of the
  solutions before the presented problems.%
    }
    \verb{doi}
    \verb 10.1002/047174882X
    \endverb
    \verb{eprint}
    \verb 20660925
    \endverb
    \field{isbn}{978-0-471-24195-9}
    \field{issn}{15579654}
    \field{pagetotal}{1\bibrangedash 748}
    \field{title}{Elements of {{Information Theory}}}
    \verb{file}
    \verb /home/casper/Zotero/storage/296ZDX75/Cover, Thomas - 2005 - Elements
    \verb of Information Theory(2).pdf
    \endverb
    \field{eprinttype}{pmid}
    \field{year}{2005}
  \endentry

  \entry{vanElteren2022}{article}{useprefix}
    \name{author}{3}{}{%
      {{hash=vEC}{%
         prefix={van},
         prefixi={v\bibinitperiod},
         family={Elteren},
         familyi={E\bibinitperiod},
         given={Casper},
         giveni={C\bibinitperiod},
      }}%
      {{hash=QR}{%
         family={Quax},
         familyi={Q\bibinitperiod},
         given={Rick},
         giveni={R\bibinitperiod},
      }}%
      {{hash=SP}{%
         family={Sloot},
         familyi={S\bibinitperiod},
         given={Peter},
         giveni={P\bibinitperiod},
      }}%
    }
    \strng{namehash}{vEC+1}
    \strng{fullhash}{vECQRSP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    One of the most central questions in network science is: which nodes are
  most important? Often this question is answered using structural properties
  such as high connectedness or centrality in the network. However, static
  structural connectedness does not necessarily translate to dynamical
  importance. To demonstrate this, we simulate the kinetic Ising spin model on
  generated networks and one real-world weighted network. The dynamic impact of
  nodes is assessed by causally intervening on node state probabilities and
  measuring the effect on the systemic dynamics. The results show that
  structural features such as network centrality or connectedness are actually
  poor predictors of the dynamical impact of a node on the rest of the network.
  A solution is offered in the form of an information theoretical measure named
  integrated mutual information. The metric is able to accurately predict the
  dynamically most important node ("driver" node) in networks based on
  observational data of non-intervened dynamics. We conclude that the driver
  node(s) in networks are not necessarily the most well-connected or central
  nodes. Indeed, the common assumption of network structural features being
  proportional to dynamical importance is false. Consequently, great care
  should be taken when deriving dynamical importance from network data alone.
  These results highlight the need for novel inference methods that take both
  structure and dynamics into account.%
    }
    \verb{doi}
    \verb 10.1016/j.physa.2022.126889
    \endverb
    \field{issn}{03784371}
    \field{pages}{126889}
    \field{shortjournal}{Physica A: Statistical Mechanics and its Applications}
    \field{title}{Dynamic Importance of Network Nodes Is Poorly Predicted by
  Static Structural Features}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/3H33TVIN/van Elteren et al. - 2022 - Dyna
    \verb mic importance of network nodes is poorly pred.pdf
    \endverb
    \field{journaltitle}{Physica A: Statistical Mechanics and its Applications}
    \field{month}{01}
    \field{year}{2022}
  \endentry

  \entry{Quax2013}{article}{}
    \name{author}{3}{}{%
      {{hash=QR}{%
         family={Quax},
         familyi={Q\bibinitperiod},
         given={Rick},
         giveni={R\bibinitperiod},
      }}%
      {{hash=AA}{%
         family={Apolloni},
         familyi={A\bibinitperiod},
         given={Andrea},
         giveni={A\bibinitperiod},
      }}%
      {{hash=aSPM}{%
         prefix={a},
         prefixi={a},
         family={Sloot},
         familyi={S\bibinitperiod},
         given={Peter\bibnamedelima M},
         giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \keyw{★,computational biology,mathematical physics,systems biology}
    \strng{namehash}{QR+1}
    \strng{fullhash}{QRAAaSPM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    It is notoriously difficult to predict the behaviour of a complex
  self-organizing system, where the interactions among dynamical units form a
  heterogeneous topology. Even if the dynamics of each microscopic unit is
  known, a real understanding of their contributions to the macroscopic system
  behaviour is still lacking. Here, we develop information-theoretical methods
  to distinguish the contribution of each individual unit to the collective
  out-of-equilibrium dynamics. We show that for a system of units connected by
  a network of interaction potentials with an arbitrary degree distribution,
  highly connected units have less impact on the system dynamics when compared
  with intermediately connected units. In an equilibrium setting, the hubs are
  often found to dictate the long-term behaviour. However, we find both
  analytically and experimentally that the instantaneous states of these units
  have a short-lasting effect on the state trajectory of the entire system. We
  present qualitative evidence of this phenomenon from empirical findings about
  a social network of product recommendations, a protein-protein interaction
  network and a neural network, suggesting that it might indeed be a widespread
  property in nature.%
    }
    \verb{doi}
    \verb 10.1098/rsif.2013.0568
    \endverb
    \verb{eprint}
    \verb 24004558
    \endverb
    \field{isbn}{1742-5689}
    \field{issn}{1742-5662}
    \field{number}{88}
    \field{pages}{20130568}
    \field{title}{The Diminishing Role of Hubs in Dynamical Processes on
  Complex Networks.}
    \field{volume}{10Q}
    \verb{file}
    \verb /home/casper/Zotero/storage/3HHYCR2N/Quax, Apolloni, Sloot - 2013 - T
    \verb he diminishing role of hubs in dynamical processes on complex network
    \verb s(2).pdf
    \endverb
    \field{journaltitle}{Journal of the Royal Society, Interface / the Royal
  Society}
    \field{eprinttype}{pmid}
    \field{year}{2013}
  \endentry

  \entry{James2016a}{article}{}
    \name{author}{3}{}{%
      {{hash=JRG}{%
         family={James},
         familyi={J\bibinitperiod},
         given={Ryan\bibnamedelima G.},
         giveni={R\bibinitperiod\bibinitdelim G\bibinitperiod},
      }}%
      {{hash=BN}{%
         family={Barnett},
         familyi={B\bibinitperiod},
         given={Nix},
         giveni={N\bibinitperiod},
      }}%
      {{hash=CJP}{%
         family={Crutchfield},
         familyi={C\bibinitperiod},
         given={James\bibnamedelima P.},
         giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
      }}%
    }
    \keyw{-a 89,05,45,50,70,75,an important task in,c 05,causation
  entropy,ey,kd 89,network science,pacs numbers,partial information
  decomposi-,stochastic process,tion,tp 02,transfer entropy,understanding a
  complex system}
    \strng{namehash}{JRG+1}
    \strng{fullhash}{JRGBNCJP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    A central task in analyzing complex dynamics is to determine the loci of
  information storage and the communication topology of information flows
  within a system. Over the last decade and a half, diagnostics for the latter
  have come to be dominated by the transfer entropy. Via straightforward
  examples, we show that it and a derivative quantity, the causation entropy,
  do not, in fact, quantify the flow of information. At one and the same time
  they can overestimate flow or underestimate influence. We isolate why this is
  the case and propose several avenues to alternate measures for information
  flow. We also address an auxiliary consequence: The proliferation of networks
  as a now-common theoretical model for large-scale systems, in concert with
  the use of transfer-like entropies, has shoehorned dyadic relationships into
  our structural interpretation of the organization and behavior of complex
  systems. This interpretation thus fails to include the effects of polyadic
  dependencies. The net result is that much of the sophisticated organization
  of complex systems may go undetected.%
    }
    \verb{doi}
    \verb 10.1103/PhysRevLett.116.238701
    \endverb
    \verb{eprint}
    \verb 27341264
    \endverb
    \field{issn}{10797114}
    \field{number}{23}
    \field{pages}{1\bibrangedash 6}
    \field{title}{Information {{Flows}}? {{A Critique}} of {{Transfer
  Entropies}}}
    \field{volume}{116}
    \verb{file}
    \verb /home/casper/Zotero/storage/285RW7MU/James, Barnett, Crutchfield - 20
    \verb 16 - Information Flows A Critique of Transfer Entropies(2).pdf
    \endverb
    \field{journaltitle}{Physical Review Letters}
    \field{eprinttype}{pmid}
    \field{year}{2016}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Beer2015}{article}{}
    \name{author}{2}{}{%
      {{hash=BRD}{%
         family={Beer},
         familyi={B\bibinitperiod},
         given={Randall\bibnamedelima D.},
         giveni={R\bibinitperiod\bibinitdelim D\bibinitperiod},
      }}%
      {{hash=WPL}{%
         family={Williams},
         familyi={W\bibinitperiod},
         given={Paul\bibnamedelima L.},
         giveni={P\bibinitperiod\bibinitdelim L\bibinitperiod},
      }}%
    }
    \keyw{Computational model,Dynamical systems theory,Evolutionary
  algorithms,Information theory,Relational categorization}
    \strng{namehash}{BRDWPL1}
    \strng{fullhash}{BRDWPL1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    There has been considerable debate in the literature about the relative
  merits of information processing versus dynamical approaches to understanding
  cognitive processes. In this article, we explore the relationship between
  these two styles of explanation using a model agent evolved to solve a
  relational categorization task. Specifically, we separately analyze the
  operation of this agent using the mathematical tools of information theory
  and dynamical systems theory. Information-theoretic analysis reveals how
  task-relevant information flows through the system to be combined into a
  categorization decision. Dynamical analysis reveals the key geometrical and
  temporal interrelationships underlying the categorization decision. Finally,
  we propose a framework for directly relating these two different styles of
  explanation and discuss the possible implications of our analysis for some of
  the ongoing debates in cognitive science.%
    }
    \verb{doi}
    \verb 10.1111/cogs.12142
    \endverb
    \field{issn}{1551-6709}
    \field{number}{1}
    \field{pages}{1\bibrangedash 38}
    \field{title}{Information {{Processing}} and {{Dynamics}} in {{Minimally
  Cognitive Agents}}}
    \field{volume}{39}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/VIJQQ6BK/Beer_Williams_2015_Information P
    \verb rocessing and Dynamics in Minimally Cognitive Agents.pdf;/home/casper
    \verb /Zotero/storage/RBBNWR7X/cogs.html
    \endverb
    \field{journaltitle}{Cognitive Science}
    \field{annotation}{%
    \_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12142%
    }
    \field{year}{2015}
  \endentry

  \entry{Kolchinsky2022}{article}{}
    \name{author}{1}{}{%
      {{hash=KA}{%
         family={Kolchinsky},
         familyi={K\bibinitperiod},
         given={Artemy},
         giveni={A\bibinitperiod},
      }}%
    }
    \strng{namehash}{KA1}
    \strng{fullhash}{KA1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    We consider the “partial information decomposition” (PID) problem,
  which aims to decompose the information that a set of source random variables
  provide about a target random variable into separate redundant, synergistic,
  union, and unique components. In the first part of this paper, we propose a
  general framework for constructing a multivariate PID. Our framework is
  defined in terms of a formal analogy with intersection and union from set
  theory, along with an ordering relation which specifies when one information
  source is more informative than another. Our definitions are algebraically
  and axiomatically motivated, and can be generalized to domains beyond Shannon
  information theory (such as algorithmic information theory and quantum
  information theory). In the second part of this paper, we use our general
  framework to define a PID in terms of the well-known Blackwell order, which
  has a fundamental operational interpretation. We demonstrate our approach on
  numerous examples and show that it overcomes many drawbacks associated with
  previous proposals.%
    }
    \verb{doi}
    \verb 10.3390/e24030403
    \endverb
    \field{issn}{1099-4300}
    \field{number}{3}
    \field{pages}{403}
    \field{shortjournal}{Entropy}
    \field{title}{A {{Novel Approach}} to the {{Partial Information
  Decomposition}}}
    \field{volume}{24}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/SZU63VWG/Kolchinsky - 2022 - A Novel Appr
    \verb oach to the Partial Information Decomp.pdf
    \endverb
    \field{journaltitle}{Entropy}
    \field{day}{13}
    \field{month}{03}
    \field{year}{2022}
  \endentry

  \entry{Williams2010}{unpublished}{}
    \name{author}{2}{}{%
      {{hash=WPL}{%
         family={Williams},
         familyi={W\bibinitperiod},
         given={Paul\bibnamedelima L.},
         giveni={P\bibinitperiod\bibinitdelim L\bibinitperiod},
      }}%
      {{hash=BRD}{%
         family={Beer},
         familyi={B\bibinitperiod},
         given={Randall\bibnamedelima D.},
         giveni={R\bibinitperiod\bibinitdelim D\bibinitperiod},
      }}%
    }
    \keyw{information theory,interaction information,multivariate
  interaction,redundancy,synergy}
    \strng{namehash}{WPLBRD1}
    \strng{fullhash}{WPLBRD1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Of the various attempts to generalize information theory to multiple
  variables, the most widely utilized, interaction information, suffers from
  the problem that it is sometimes negative. Here we reconsider from first
  principles the general structure of the information that a set of sources
  provides about a given variable. We begin with a new definition of redundancy
  as the minimum information that any source provides about each possible
  outcome of the variable, averaged over all possible outcomes. We then show
  how this measure of redundancy induces a lattice over sets of sources that
  clarifies the general structure of multivariate information. Finally, we use
  this redundancy lattice to propose a definition of partial information atoms
  that exhaustively decompose the Shannon information in a multivariate system
  in terms of the redundancy between synergies of subsets of the sources.
  Unlike interaction information, the atoms of our partial information
  decomposition are never negative and always support a clear interpretation as
  informational quantities. Our analysis also demonstrates how the negativity
  of interaction information can be explained by its confounding of redundancy
  and synergy.%
    }
    \verb{eprint}
    \verb 1004.2515
    \endverb
    \field{pages}{1\bibrangedash 14}
    \field{title}{Nonnegative {{Decomposition}} of {{Multivariate
  Information}}}
    \verb{url}
    \verb http://arxiv.org/abs/1004.2515
    \endverb
    \field{eprinttype}{arxiv}
    \field{year}{2010}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Forgoston2018}{article}{}
    \name{author}{2}{}{%
      {{hash=FE}{%
         family={Forgoston},
         familyi={F\bibinitperiod},
         given={Eric},
         giveni={E\bibinitperiod},
      }}%
      {{hash=MRO}{%
         family={Moore},
         familyi={M\bibinitperiod},
         given={Richard\bibnamedelima O.},
         giveni={R\bibinitperiod\bibinitdelim O\bibinitperiod},
      }}%
    }
    \keyw{37H10 60F10 78A60 92D25 82C26,Condensed Matter - Statistical
  Mechanics,Mathematics - Analysis of PDEs,Mathematics -
  Probability,Quantitative Biology - Populations and Evolution}
    \strng{namehash}{FEMRO1}
    \strng{fullhash}{FEMRO1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Noise plays a fundamental role in a wide variety of physical and biological
  dynamical systems. It can arise from an external forcing or due to random
  dynamics internal to the system. It is well established that even weak noise
  can result in large behavioral changes such as transitions between or escapes
  from quasi-stable states. These transitions can correspond to critical events
  such as failures or extinctions that make them essential phenomena to
  understand and quantify, despite the fact that their occurrence is rare. This
  article will provide an overview of the theory underlying the dynamics of
  rare events for stochastic models along with some example applications.%
    }
    \verb{doi}
    \verb 10.1137/17M1142028
    \endverb
    \verb{eprint}
    \verb 1712.03785
    \endverb
    \field{issn}{0036-1445, 1095-7200}
    \field{number}{4}
    \field{pages}{969\bibrangedash 1009}
    \field{shortjournal}{SIAM Rev.}
    \field{title}{A Primer on Noise-Induced Transitions in Applied Dynamical
  Systems}
    \field{volume}{60}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/8ED7F67X/Forgoston and Moore - 2018 - A p
    \verb rimer on noise-induced transitions in applied d.pdf
    \endverb
    \field{journaltitle}{SIAM Review}
    \field{eprinttype}{arxiv}
    \field{month}{01}
    \field{year}{2018}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Calim2021}{article}{}
    \name{author}{3}{}{%
      {{hash=CA}{%
         family={Calim},
         familyi={C\bibinitperiod},
         given={Ali},
         giveni={A\bibinitperiod},
      }}%
      {{hash=PT}{%
         family={Palabas},
         familyi={P\bibinitperiod},
         given={Tugba},
         giveni={T\bibinitperiod},
      }}%
      {{hash=UM}{%
         family={Uzuntarla},
         familyi={U\bibinitperiod},
         given={Muhammet},
         giveni={M\bibinitperiod},
      }}%
    }
    \strng{namehash}{CA+1}
    \strng{fullhash}{CAPTUM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    The concept of resonance in nonlinear systems is crucial and traditionally
  refers to a specific realization of maximum response provoked by a particular
  external perturbation. Depending on the system and the nature of
  perturbation, many different resonance types have been identified in various
  fields of science. A prominent example is in neuroscience where it has been
  widely accepted that a neural system may exhibit resonances at microscopic,
  mesoscopic and macroscopic scales and benefit from such resonances in various
  tasks. In this context, the two well-known forms are stochastic and
  vibrational resonance phenomena which manifest that detection and propagation
  of a feeble information signal in neural structures can be enhanced by
  additional perturbations via these two resonance mechanisms. Given the
  importance of network architecture in proper functioning of the nervous
  system, we here present a review of recent studies on stochastic and
  vibrational resonance phenomena in neuronal media, focusing mainly on their
  emergence in complex networks of neurons as well as in simple network
  structures that represent local behaviours of neuron communities. From this
  perspective, we aim to provide a secure guide by including theoretical and
  experimental approaches that analyse in detail possible reasons and necessary
  conditions for the appearance of stochastic resonance and vibrational
  resonance in neural systems. This article is part of the theme issue
  ‘Vibrational and stochastic resonance in driven nonlinear systems (part
  2)’.%
    }
    \verb{doi}
    \verb 10.1098/rsta.2020.0236
    \endverb
    \field{issn}{1364-503X, 1471-2962}
    \field{number}{2198}
    \field{pages}{rsta.2020.0236, 20200236}
    \field{shortjournal}{Phil. Trans. R. Soc. A.}
    \field{title}{Stochastic and Vibrational Resonance in Complex Networks of
  Neurons}
    \field{volume}{379}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/399EZSZT/Calim et al. - 2021 - Stochastic
    \verb  and vibrational resonance in complex ne.pdf
    \endverb
    \field{journaltitle}{Philosophical Transactions of the Royal Society A:
  Mathematical, Physical and Engineering Sciences}
    \field{day}{31}
    \field{month}{05}
    \field{year}{2021}
  \endentry

  \entry{Czaplicka2013a}{article}{}
    \name{author}{3}{}{%
      {{hash=CA}{%
         family={Czaplicka},
         familyi={C\bibinitperiod},
         given={Agnieszka},
         giveni={A\bibinitperiod},
      }}%
      {{hash=HJA}{%
         family={Holyst},
         familyi={H\bibinitperiod},
         given={Janusz\bibnamedelima A.},
         giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod},
      }}%
      {{hash=SPM}{%
         family={Sloot},
         familyi={S\bibinitperiod},
         given={Peter\bibnamedelima M.A.},
         giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \keyw{statistical physics}
    \strng{namehash}{CA+2}
    \strng{fullhash}{CAHJASPM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    We study the influence of noise on information transmission in the form of
  packages shipped between nodes of hierarchical networks. Numerical
  simulations are performed for artificial tree networks, scale-free
  Ravasz-Barabási networks as well for a real network formed by email
  addresses of former Enron employees. Two types of noise are considered. One
  is related to packet dynamics and is responsible for a random part of packets
  paths. The second one originates from random changes in initial network
  topology. We find that the information transfer can be enhanced by the noise.
  The system possesses optimal performance when both kinds of noise are tuned
  to specific values, this corresponds to the Stochastic Resonance phenomenon.
  There is a non-trivial synergy present for both noisy components. We found
  also that hierarchical networks built of nodes of various degrees are more
  efficient in information transfer than trees with a fixed branching factor.%
    }
    \verb{doi}
    \verb 10.1038/srep01223
    \endverb
    \field{issn}{20452322}
    \field{title}{Noise Enhances Information Transfer in Hierarchical Networks}
    \field{volume}{3}
    \field{journaltitle}{Scientific Reports}
    \field{year}{2013}
  \endentry

  \entry{Lizier2008}{article}{}
    \name{author}{3}{}{%
      {{hash=LJT}{%
         family={Lizier},
         familyi={L\bibinitperiod},
         given={Joseph\bibnamedelima T},
         giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
      }}%
      {{hash=PM}{%
         family={Prokopenko},
         familyi={P\bibinitperiod},
         given={Mikhail},
         giveni={M\bibinitperiod},
      }}%
      {{hash=ZAY}{%
         family={Zomaya},
         familyi={Z\bibinitperiod},
         given={Albert\bibnamedelima Y},
         giveni={A\bibinitperiod\bibinitdelim Y\bibinitperiod},
      }}%
    }
    \strng{namehash}{LJT+2}
    \strng{fullhash}{LJTPMZAY1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Random Boolean Networks (RBNs) are discrete dynamical systems which have
  been used to model Gene Regulatory Networks. We investigate the well-known
  phase transition between ordered and chaotic behavior in RBNs from the
  perspective of the distributed computation conducted by their nodes. We use a
  recently published framework to characterize the distributed computation in
  terms of its underlying information dynamics: information storage,
  information transfer and information modification. We find maximizations in
  information storage and coherent information transfer on either side of the
  critical point, allowing us to explain the phase transition in RBNs in terms
  of the intrinsic distributed computations they are undertaking.%
    }
    \field{pages}{9}
    \field{title}{The {{Information Dynamics}} of {{Phase Transitions}} in
  {{Random Boolean Networks}}}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/JW4JIHWK/Lizier et al. - 2008 - The Infor
    \verb mation Dynamics of Phase Transitions in R.pdf
    \endverb
    \field{year}{2008}
  \endentry

  \entry{Lizier2013}{article}{}
    \name{author}{3}{}{%
      {{hash=LJT}{%
         family={Lizier},
         familyi={L\bibinitperiod},
         given={Joseph\bibnamedelima T.},
         giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
      }}%
      {{hash=FB}{%
         family={Flecker},
         familyi={F\bibinitperiod},
         given={Benjamin},
         giveni={B\bibinitperiod},
      }}%
      {{hash=WPL}{%
         family={Williams},
         familyi={W\bibinitperiod},
         given={Paul\bibnamedelima L.},
         giveni={P\bibinitperiod\bibinitdelim L\bibinitperiod},
      }}%
    }
    \strng{namehash}{LJT+1}
    \strng{fullhash}{LJTFBWPL1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Distributed computation in artificial life and complex systems is often
  described in terms of component operations on information: information
  storage, transfer and modification. Information modification remains poorly
  described however, with the popularly-understood examples of glider and
  particle collisions in cellular automata being only quantitatively identified
  to date using a heuristic (separable information) rather than a proper
  information-theoretic measure. We outline how a recently-introduced axiomatic
  framework for measuring information redundancy and synergy, called partial
  information decomposition, can be applied to a perspective of distributed
  computation in order to quantify component operations on information. Using
  this framework, we propose a new measure of information modification that
  captures the intuitive understanding of information modification events as
  those involving interactions between two or more information sources. We also
  consider how the local dynamics of information modification in space and time
  could be measured, and suggest a new axiom that redundancy measures would
  need to meet in order to make such local measurements. Finally, we evaluate
  the potential for existing redundancy measures to meet this localizability
  axiom.%
    }
    \verb{doi}
    \verb 10.1109/ALIFE.2013.6602430
    \endverb
    \verb{eprint}
    \verb 1303.3440
    \endverb
    \field{isbn}{978-1-4673-5863-7}
    \field{issn}{21606382}
    \field{issue}{January}
    \field{pages}{43\bibrangedash 51}
    \field{title}{Towards a Synergy-Based Approach to Measuring Information
  Modification}
    \field{volume}{2013-Janua}
    \field{journaltitle}{IEEE Symposium on Artificial Life (ALIFE)}
    \field{eprinttype}{arxiv}
    \field{year}{2013}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Lizier2018}{article}{}
    \name{author}{4}{}{%
      {{hash=LJT}{%
         family={Lizier},
         familyi={L\bibinitperiod},
         given={Joseph\bibnamedelima T.},
         giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
      }}%
      {{hash=BN}{%
         family={Bertschinger},
         familyi={B\bibinitperiod},
         given={Nils},
         giveni={N\bibinitperiod},
      }}%
      {{hash=JJ}{%
         family={Jost},
         familyi={J\bibinitperiod},
         given={Jürgen},
         giveni={J\bibinitperiod},
      }}%
      {{hash=WM}{%
         family={Wibral},
         familyi={W\bibinitperiod},
         given={Michael},
         giveni={M\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{Multidisciplinary Digital Publishing Institute}}%
    }
    \keyw{complementary information,information decomposition,mutual
  information,redundancy,redundant information,synergy,unique information}
    \strng{namehash}{LJT+1}
    \strng{fullhash}{LJTBNJJWM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{abstract}{%
    The formulation of the Partial Information Decomposition (PID) framework by
  Williams and Beer in 2010 attracted a significant amount of attention to the
  problem of defining redundant (or shared), unique and synergistic (or
  complementary) components of mutual information that a set of source
  variables provides about a target. This attention resulted in a number of
  measures proposed to capture these concepts, theoretical investigations into
  such measures, and applications to empirical data (in particular to datasets
  from neuroscience). In this Special Issue on “Information Decomposition of
  Target Effects from Multi-Source Interactions” at Entropy, we have gathered
  current work on such information decomposition approaches from many of the
  leading research groups in the field. We begin our editorial by providing the
  reader with a review of previous information decomposition research,
  including an overview of the variety of measures proposed, how they have been
  interpreted and applied to empirical investigations. We then introduce the
  articles included in the special issue one by one, providing a similar
  categorisation of these articles into: i. proposals of new measures; ii.
  theoretical investigations into properties and interpretations of such
  approaches, and iii. applications of these measures in empirical studies. We
  finish by providing an outlook on the future of the field.%
    }
    \verb{doi}
    \verb 10.3390/e20040307
    \endverb
    \field{issue}{4}
    \field{number}{4}
    \field{pages}{307}
    \field{shorttitle}{Information {{Decomposition}} of {{Target Effects}} from
  {{Multi-Source Interactions}}}
    \field{title}{Information {{Decomposition}} of {{Target Effects}} from
  {{Multi-Source Interactions}}: {{Perspectives}} on {{Previous}}, {{Current}}
  and {{Future Work}}}
    \field{volume}{20}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/W37QKSHM/Lizier et al_2018_Information De
    \verb composition of Target Effects from Multi-Source Interactions.pdf;/hom
    \verb e/casper/Zotero/storage/WXAC7IMT/307.html
    \endverb
    \field{journaltitle}{Entropy}
    \field{month}{04}
    \field{year}{2018}
  \endentry

  \entry{Quax2017}{article}{}
    \name{author}{3}{}{%
      {{hash=QR}{%
         family={Quax},
         familyi={Q\bibinitperiod},
         given={Rick},
         giveni={R\bibinitperiod},
      }}%
      {{hash=HSO}{%
         family={Har-Shemesh},
         familyi={H\bibinithyphendelim S\bibinitperiod},
         given={Omri},
         giveni={O\bibinitperiod},
      }}%
      {{hash=SPM}{%
         family={Sloot},
         familyi={S\bibinitperiod},
         given={Peter\bibnamedelima M.A.},
         giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \keyw{Higher order information,Information theory,Stochastic
  variables,Synergistic entropy,Synergistic information,Synergy}
    \strng{namehash}{QR+1}
    \strng{fullhash}{QRHSOSPM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Quantifying synergy among stochastic variables is an important open problem
  in information theory. Information synergy occurs when multiple sources
  together predict an outcome variable better than the sum of single-source
  predictions. It is an essential phenomenon in biology such as in neuronal
  networks and cellular regulatory processes, where different information flows
  integrate to produce a single response, but also in social cooperation
  processes as well as in statistical inference tasks in machine learning. Here
  we propose a metric of synergistic entropy and synergistic information from
  first principles. The proposed measure relies on so-called synergistic random
  variables (SRVs) which are constructed to have zero mutual information about
  individual source variables but non-zero mutual information about the
  complete set of source variables. We prove several basic and desired
  properties of our measure, including bounds and additivity properties. In
  addition, we prove several important consequences of our measure, including
  the fact that different types of synergistic information may co-exist between
  the same sets of variables. A numerical implementation is provided, which we
  use to demonstrate that synergy is associated with resilience to noise. Our
  measure may be a marked step forward in the study of multivariate information
  theory and its numerous applications.%
    }
    \verb{doi}
    \verb 10.3390/e19020085
    \endverb
    \verb{eprint}
    \verb 1602.01265
    \endverb
    \field{issn}{10994300}
    \field{number}{2}
    \field{pages}{7\bibrangedash 10}
    \field{title}{Quantifying Synergistic Information Using Intermediate
  Stochastic Variables}
    \field{volume}{19}
    \verb{file}
    \verb /home/casper/Zotero/storage/H3ZPMP8K/Quax, Har-Shemesh, Sloot - 2017
    \verb - Quantifying synergistic information using intermediate stochastic v
    \verb ariables(2).pdf
    \endverb
    \field{journaltitle}{Entropy}
    \field{eprinttype}{arxiv}
    \field{year}{2017}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Lizier2010}{article}{}
    \name{author}{3}{}{%
      {{hash=LJT}{%
         family={Lizier},
         familyi={L\bibinitperiod},
         given={Joseph\bibnamedelima T.},
         giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
      }}%
      {{hash=PM}{%
         family={Prokopenko},
         familyi={P\bibinitperiod},
         given={Mikhail},
         giveni={M\bibinitperiod},
      }}%
      {{hash=ZAY}{%
         family={Zomaya},
         familyi={Z\bibinitperiod},
         given={Albert\bibnamedelima Y.},
         giveni={A\bibinitperiod\bibinitdelim Y\bibinitperiod},
      }}%
    }
    \strng{namehash}{LJT+3}
    \strng{fullhash}{LJTPMZAY2}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \verb{doi}
    \verb 10.1063/1.3486801
    \endverb
    \field{issn}{1054-1500, 1089-7682}
    \field{number}{3}
    \field{pages}{037109}
    \field{shortjournal}{Chaos}
    \field{title}{Information Modification and Particle Collisions in
  Distributed Computation}
    \field{volume}{20}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/6QDDKZ4Z/Lizier et al. - 2010 - Informati
    \verb on modification and particle collisions i.pdf
    \endverb
    \field{journaltitle}{Chaos: An Interdisciplinary Journal of Nonlinear
  Science}
    \field{month}{09}
    \field{year}{2010}
  \endentry

  \entry{Scheffer2009}{article}{useprefix}
    \name{author}{10}{}{%
      {{hash=SM}{%
         family={Scheffer},
         familyi={S\bibinitperiod},
         given={Marten},
         giveni={M\bibinitperiod},
      }}%
      {{hash=BJ}{%
         family={Bascompte},
         familyi={B\bibinitperiod},
         given={Jordi},
         giveni={J\bibinitperiod},
      }}%
      {{hash=BWA}{%
         family={Brock},
         familyi={B\bibinitperiod},
         given={William\bibnamedelima A},
         giveni={W\bibinitperiod\bibinitdelim A\bibinitperiod},
      }}%
      {{hash=BV}{%
         family={Brovkin},
         familyi={B\bibinitperiod},
         given={Victor},
         giveni={V\bibinitperiod},
      }}%
      {{hash=CSR}{%
         family={Carpenter},
         familyi={C\bibinitperiod},
         given={Stephen\bibnamedelima R},
         giveni={S\bibinitperiod\bibinitdelim R\bibinitperiod},
      }}%
      {{hash=DV}{%
         family={Dakos},
         familyi={D\bibinitperiod},
         given={Vasilis},
         giveni={V\bibinitperiod},
      }}%
      {{hash=HH}{%
         family={Held},
         familyi={H\bibinitperiod},
         given={Hermann},
         giveni={H\bibinitperiod},
      }}%
      {{hash=vNEH}{%
         prefix={van},
         prefixi={v\bibinitperiod},
         family={Nes},
         familyi={N\bibinitperiod},
         given={Egbert\bibnamedelima H},
         giveni={E\bibinitperiod\bibinitdelim H\bibinitperiod},
      }}%
      {{hash=RM}{%
         family={Rietkerk},
         familyi={R\bibinitperiod},
         given={Max},
         giveni={M\bibinitperiod},
      }}%
      {{hash=SG}{%
         family={Sugihara},
         familyi={S\bibinitperiod},
         given={George},
         giveni={G\bibinitperiod},
      }}%
    }
    \strng{namehash}{SM+1}
    \strng{fullhash}{SMBJBWABVCSRDVHHvNEHRMSG1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Complex dynamical systems, ranging from ecosystems to financial markets and
  the climate, can have tipping points at which a sudden shift to a contrasting
  dynamical regime may occur. Although predicting such critical points before
  they are reached is extremely difficult, work in different scientific fields
  is now suggesting the existence of generic early-warning signals that may
  indicate for a wide class of systems if a critical threshold is approaching.%
    }
    \verb{doi}
    \verb 10.1038/nature08227
    \endverb
    \verb{eprint}
    \verb 19727193
    \endverb
    \field{issn}{1476-4687}
    \field{number}{7260}
    \field{pages}{53\bibrangedash 9}
    \field{title}{Early-Warning Signals for Critical Transitions.}
    \field{volume}{461}
    \field{journaltitle}{Nature}
    \field{eprinttype}{pmid}
    \field{year}{2009}
  \endentry

  \entry{Prokopenko2011}{article}{}
    \name{author}{4}{}{%
      {{hash=PM}{%
         family={Prokopenko},
         familyi={P\bibinitperiod},
         given={Mikhail},
         giveni={M\bibinitperiod},
      }}%
      {{hash=LJT}{%
         family={Lizier},
         familyi={L\bibinitperiod},
         given={Joseph\bibnamedelima T.},
         giveni={J\bibinitperiod\bibinitdelim T\bibinitperiod},
      }}%
      {{hash=OO}{%
         family={Obst},
         familyi={O\bibinitperiod},
         given={Oliver},
         giveni={O\bibinitperiod},
      }}%
      {{hash=WXR}{%
         family={Wang},
         familyi={W\bibinitperiod},
         given={X.\bibnamedelima Rosalind},
         giveni={X\bibinitperiod\bibinitdelim R\bibinitperiod},
      }}%
    }
    \strng{namehash}{PM+1}
    \strng{fullhash}{PMLJTOOWXR1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \verb{doi}
    \verb 10.1103/PhysRevE.84.041116
    \endverb
    \field{issn}{1539-3755, 1550-2376}
    \field{number}{4}
    \field{pages}{041116}
    \field{shortjournal}{Phys. Rev. E}
    \field{title}{Relating {{Fisher}} Information to Order Parameters}
    \field{volume}{84}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/WVCZP9V3/Prokopenko et al. - 2011 - Relat
    \verb ing Fisher information to order parameters.pdf
    \endverb
    \field{journaltitle}{Physical Review E}
    \field{day}{13}
    \field{month}{10}
    \field{year}{2011}
  \endentry

  \entry{Scheffer2001}{article}{}
    \name{author}{5}{}{%
      {{hash=SM}{%
         family={Scheffer},
         familyi={S\bibinitperiod},
         given={Marten},
         giveni={M\bibinitperiod},
      }}%
      {{hash=CS}{%
         family={Carpenter},
         familyi={C\bibinitperiod},
         given={Steve},
         giveni={S\bibinitperiod},
      }}%
      {{hash=FJA}{%
         family={Foley},
         familyi={F\bibinitperiod},
         given={Jonathan\bibnamedelima A.},
         giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod},
      }}%
      {{hash=FC}{%
         family={Folke},
         familyi={F\bibinitperiod},
         given={Carl},
         giveni={C\bibinitperiod},
      }}%
      {{hash=WB}{%
         family={Walker},
         familyi={W\bibinitperiod},
         given={Brian},
         giveni={B\bibinitperiod},
      }}%
    }
    \strng{namehash}{SM+1}
    \strng{fullhash}{SMCSFJAFCWB1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \verb{doi}
    \verb 10.1038/35098000
    \endverb
    \field{issn}{0028-0836, 1476-4687}
    \field{number}{6856}
    \field{pages}{591\bibrangedash 596}
    \field{shortjournal}{Nature}
    \field{title}{Catastrophic Shifts in Ecosystems}
    \field{volume}{413}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/9PC6GLB5/Scheffer et al. - 2001 - Catastr
    \verb ophic shifts in ecosystems.pdf
    \endverb
    \field{journaltitle}{Nature}
    \field{month}{10}
    \field{year}{2001}
  \endentry

  \entry{Eason2014}{article}{}
    \name{author}{3}{}{%
      {{hash=ET}{%
         family={Eason},
         familyi={E\bibinitperiod},
         given={Tarsha},
         giveni={T\bibinitperiod},
      }}%
      {{hash=GAS}{%
         family={Garmestani},
         familyi={G\bibinitperiod},
         given={Ahjond\bibnamedelima S.},
         giveni={A\bibinitperiod\bibinitdelim S\bibinitperiod},
      }}%
      {{hash=CH}{%
         family={Cabezas},
         familyi={C\bibinitperiod},
         given={Heriberto},
         giveni={H\bibinitperiod},
      }}%
    }
    \strng{namehash}{ET+1}
    \strng{fullhash}{ETGASCH1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{shorttitle}
    \field{abstract}{%
    The broad implications of catastrophic regime shifts have prompted the need
  to find methods that are not only able to detect regime shifts but more
  importantly, identify them before they occur. Rising variance, skewness,
  kurtosis, and critical slowing down have all been proposed as indicators of
  impending regime shifts. However, these approaches typically do not signal a
  shift until it is well underway. Further, they have primarily been used to
  evaluate simple systems; hence, additional work is needed to adapt these
  methods, if possible, to real systems which typically are complex and
  multivariate. Fisher information is a key method in information theory and
  affords the ability to characterize the dynamic behavior of systems. In this
  work, Fisher information is compared to traditional indicators through the
  assessment of model and real systems and identified as a leading indicator of
  impending regime shifts. Evidenced by the great deal of activity in this
  research area, it is understood that such work could lead to better methods
  for detecting and managing systems that are of significant importance to
  humans. Thus, we believe the results of this work offer great promise for
  resilience science and sustainability.%
    }
    \verb{doi}
    \verb 10.1007/s10098-013-0687-2
    \endverb
    \field{issn}{1618-954X, 1618-9558}
    \field{number}{4}
    \field{pages}{773\bibrangedash 783}
    \field{shortjournal}{Clean Techn Environ Policy}
    \field{shorttitle}{Managing for Resilience}
    \field{title}{Managing for Resilience: Early Detection of Regime Shifts in
  Complex Systems}
    \field{volume}{16}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/5AJ9RRBF/Eason et al. - 2014 - Managing f
    \verb or resilience early detection of regime.pdf
    \endverb
    \field{journaltitle}{Clean Technologies and Environmental Policy}
    \field{month}{04}
    \field{year}{2014}
  \endentry

  \entry{Schreiber}{book}{}
    \name{author}{1}{}{%
      {{hash=SM}{%
         family={Schreiber},
         familyi={S\bibinitperiod},
         given={M},
         giveni={M},
      }}%
    }
    \strng{namehash}{SM1}
    \strng{fullhash}{SM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{isbn}{978-3-642-46246-7}
    \field{title}{Volume 1 {{Edited}} by {{K}}. {{Krickeberg}}· {{R}}. {{C}}.
  {{Lewontin}} . {{J}}. {{Neyman M}}. {{Schreiber}}}
    \field{volume}{1}
  \endentry

  \entry{Ay2008}{article}{}
    \name{author}{2}{}{%
      {{hash=AN}{%
         family={Ay},
         familyi={A\bibinitperiod},
         given={Nihat},
         giveni={N\bibinitperiod},
      }}%
      {{hash=PD}{%
         family={Polani},
         familyi={P\bibinitperiod},
         given={Daniel},
         giveni={D\bibinitperiod},
      }}%
    }
    \keyw{bayesian networks,causality,information flow,information theory}
    \strng{namehash}{ANPD1}
    \strng{fullhash}{ANPD1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    We use a notion of causal independence based on intervention, which is a
  fundamental concept of the theory of causal networks, to define a measure for
  the strength of a causal effect. We call this measure " information flow "
  and compare it with known information flow measures such as transfer
  entropy.%
    }
    \verb{doi}
    \verb 10.1142/S0219525908001465
    \endverb
    \verb{eprint}
    \verb 15823657
    \endverb
    \field{isbn}{0219-5259}
    \field{issn}{0219-5259}
    \field{number}{01}
    \field{pages}{17\bibrangedash 41}
    \field{title}{Information {{Flows}} in {{Causal Networks}}}
    \field{volume}{11}
    \verb{file}
    \verb /home/casper/Zotero/storage/DBASDI5W/Ay, Polani - 2008 - Information
    \verb Flows in Causal Networks(2).pdf
    \endverb
    \field{journaltitle}{Advances in Complex Systems}
    \field{eprinttype}{pmid}
    \field{year}{2008}
  \endentry

  \entry{Runge2019}{article}{useprefix}
    \name{author}{21}{}{%
      {{hash=RJ}{%
         family={Runge},
         familyi={R\bibinitperiod},
         given={Jakob},
         giveni={J\bibinitperiod},
      }}%
      {{hash=BS}{%
         family={Bathiany},
         familyi={B\bibinitperiod},
         given={Sebastian},
         giveni={S\bibinitperiod},
      }}%
      {{hash=BE}{%
         family={Bollt},
         familyi={B\bibinitperiod},
         given={Erik},
         giveni={E\bibinitperiod},
      }}%
      {{hash=CVG}{%
         family={Camps-Valls},
         familyi={C\bibinithyphendelim V\bibinitperiod},
         given={Gustau},
         giveni={G\bibinitperiod},
      }}%
      {{hash=CD}{%
         family={Coumou},
         familyi={C\bibinitperiod},
         given={Dim},
         giveni={D\bibinitperiod},
      }}%
      {{hash=DE}{%
         family={Deyle},
         familyi={D\bibinitperiod},
         given={Ethan},
         giveni={E\bibinitperiod},
      }}%
      {{hash=GC}{%
         family={Glymour},
         familyi={G\bibinitperiod},
         given={Clark},
         giveni={C\bibinitperiod},
      }}%
      {{hash=KM}{%
         family={Kretschmer},
         familyi={K\bibinitperiod},
         given={Marlene},
         giveni={M\bibinitperiod},
      }}%
      {{hash=MMD}{%
         family={Mahecha},
         familyi={M\bibinitperiod},
         given={Miguel\bibnamedelima D.},
         giveni={M\bibinitperiod\bibinitdelim D\bibinitperiod},
      }}%
      {{hash=MMJ}{%
         family={Muñoz-Marí},
         familyi={M\bibinithyphendelim M\bibinitperiod},
         given={Jordi},
         giveni={J\bibinitperiod},
      }}%
      {{hash=vNEH}{%
         prefix={van},
         prefixi={v\bibinitperiod},
         family={Nes},
         familyi={N\bibinitperiod},
         given={Egbert\bibnamedelima H.},
         giveni={E\bibinitperiod\bibinitdelim H\bibinitperiod},
      }}%
      {{hash=PJ}{%
         family={Peters},
         familyi={P\bibinitperiod},
         given={Jonas},
         giveni={J\bibinitperiod},
      }}%
      {{hash=QR}{%
         family={Quax},
         familyi={Q\bibinitperiod},
         given={Rick},
         giveni={R\bibinitperiod},
      }}%
      {{hash=RM}{%
         family={Reichstein},
         familyi={R\bibinitperiod},
         given={Markus},
         giveni={M\bibinitperiod},
      }}%
      {{hash=SM}{%
         family={Scheffer},
         familyi={S\bibinitperiod},
         given={Marten},
         giveni={M\bibinitperiod},
      }}%
      {{hash=SB}{%
         family={Schölkopf},
         familyi={S\bibinitperiod},
         given={Bernhard},
         giveni={B\bibinitperiod},
      }}%
      {{hash=SP}{%
         family={Spirtes},
         familyi={S\bibinitperiod},
         given={Peter},
         giveni={P\bibinitperiod},
      }}%
      {{hash=SG}{%
         family={Sugihara},
         familyi={S\bibinitperiod},
         given={George},
         giveni={G\bibinitperiod},
      }}%
      {{hash=SJ}{%
         family={Sun},
         familyi={S\bibinitperiod},
         given={Jie},
         giveni={J\bibinitperiod},
      }}%
      {{hash=ZK}{%
         family={Zhang},
         familyi={Z\bibinitperiod},
         given={Kun},
         giveni={K\bibinitperiod},
      }}%
      {{hash=ZJ}{%
         family={Zscheischler},
         familyi={Z\bibinitperiod},
         given={Jakob},
         giveni={J\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{Springer US}}%
    }
    \strng{namehash}{RJ+1}
    \strng{fullhash}{RJBSBECVGCDDEGCKMMMDMMJvNEHPJQRRMSMSBSPSGSJZKZJ1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    The heart of the scientific enterprise is a rational effort to understand
  the causes behind the phenomena we observe. In large-scale complex dynamical
  systems such as the Earth system, real experiments are rarely feasible.
  However, a rapidly increasing amount of observational and simulated data
  opens up the use of novel data-driven causal methods beyond the commonly
  adopted correlation techniques. Here, we give an overview of causal inference
  frameworks and identify promising generic application cases common in Earth
  system sciences and beyond. We discuss challenges and initiate the benchmark
  platform causeme.net to close the gap between method users and developers.%
    }
    \verb{doi}
    \verb 10.1038/s41467-019-10105-3
    \endverb
    \verb{eprint}
    \verb 31201306
    \endverb
    \field{isbn}{4146701910}
    \field{issn}{20411723}
    \field{number}{1}
    \field{pages}{1\bibrangedash 13}
    \field{title}{Inferring Causation from Time Series in {{Earth}} System
  Sciences}
    \field{volume}{10}
    \field{journaltitle}{Nature Communications}
    \field{eprinttype}{pmid}
    \field{year}{2019}
  \endentry

  \entry{Li2008}{article}{}
    \name{author}{1}{}{%
      {{hash=LC}{%
         family={Li},
         familyi={L\bibinitperiod},
         given={Chunguang},
         giveni={C\bibinitperiod},
      }}%
    }
    \strng{namehash}{LC1}
    \strng{fullhash}{LC1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \verb{doi}
    \verb 10.1103/PhysRevE.78.037101
    \endverb
    \field{issn}{1539-3755, 1550-2376}
    \field{number}{3}
    \field{pages}{037101}
    \field{shortjournal}{Phys. Rev. E}
    \field{title}{Functions of Neuronal Network Motifs}
    \field{volume}{78}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/GQQ2BVL7/Li - 2008 - Functions of neurona
    \verb l network motifs.pdf
    \endverb
    \field{journaltitle}{Physical Review E}
    \field{day}{03}
    \field{month}{09}
    \field{year}{2008}
  \endentry

  \entry{James2016}{article}{}
    \name{author}{3}{}{%
      {{hash=JRG}{%
         family={James},
         familyi={J\bibinitperiod},
         given={Ryan\bibnamedelima G.},
         giveni={R\bibinitperiod\bibinitdelim G\bibinitperiod},
      }}%
      {{hash=BN}{%
         family={Barnett},
         familyi={B\bibinitperiod},
         given={Nix},
         giveni={N\bibinitperiod},
      }}%
      {{hash=CJP}{%
         family={Crutchfield},
         familyi={C\bibinitperiod},
         given={James\bibnamedelima P.},
         giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
      }}%
    }
    \keyw{-a 89,05,45,50,70,75,an important task in,c 05,causation
  entropy,ey,kd 89,network science,pacs numbers,partial information
  decomposi-,stochastic process,tion,tp 02,transfer entropy,understanding a
  complex system}
    \strng{namehash}{JRG+1}
    \strng{fullhash}{JRGBNCJP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    A central task in analyzing complex dynamics is to determine the loci of
  information storage and the communication topology of information flows
  within a system. Over the last decade and a half, diagnostics for the latter
  have come to be dominated by the transfer entropy. Via straightforward
  examples, we show that it and a derivative quantity, the causation entropy,
  do not, in fact, quantify the flow of information. At one and the same time
  they can overestimate flow or underestimate influence. We isolate why this is
  the case and propose several avenues to alternate measures for information
  flow. We also address an auxiliary consequence: The proliferation of networks
  as a now-common theoretical model for large-scale systems, in concert with
  the use of transfer-like entropies, has shoehorned dyadic relationships into
  our structural interpretation of the organization and behavior of complex
  systems. This interpretation thus fails to include the effects of polyadic
  dependencies. The net result is that much of the sophisticated organization
  of complex systems may go undetected.%
    }
    \verb{doi}
    \verb 10.1103/PhysRevLett.116.238701
    \endverb
    \verb{eprint}
    \verb 27341264
    \endverb
    \field{issn}{10797114}
    \field{number}{23}
    \field{pages}{1\bibrangedash 6}
    \field{title}{Information {{Flows}}? {{A Critique}} of {{Transfer
  Entropies}}}
    \field{volume}{116}
    \verb{file}
    \verb /home/casper/Zotero/storage/UYJ9A9ZX/James, Barnett, Crutchfield - 20
    \verb 16 - Information Flows A Critique of Transfer Entropies(2).pdf
    \endverb
    \field{journaltitle}{Physical Review Letters}
    \field{eprinttype}{pmid}
    \field{year}{2016}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Bialek1999}{misc}{}
    \name{author}{2}{}{%
      {{hash=BW}{%
         family={Bialek},
         familyi={B\bibinitperiod},
         given={William},
         giveni={W\bibinitperiod},
      }}%
      {{hash=TN}{%
         family={Tishby},
         familyi={T\bibinitperiod},
         given={Naftali},
         giveni={N\bibinitperiod},
      }}%
    }
    \list{publisher}{1}{%
      {{arXiv}}%
    }
    \keyw{Condensed Matter - Disordered Systems and Neural Networks,Condensed
  Matter - Statistical Mechanics,Quantitative Biology - Neurons and Cognition}
    \strng{namehash}{BWTN1}
    \strng{fullhash}{BWTN1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    Observations on the past provide some hints about what will happen in the
  future, and this can be quantified using information theory. The ``predictive
  information'' defined in this way has connections to measures of complexity
  that have been proposed both in the study of dynamical systems and in
  mathematical statistics. In particular, the predictive information diverges
  when the observed data stream allows us to learn an increasingly precise
  model for the dynamics that generate the data, and the structure of this
  divergence measures the complexity of the model. We argue that divergent
  contributions to the predictive information provide the only measure of
  complexity or richness that is consistent with certain plausible
  requirements.%
    }
    \verb{eprint}
    \verb cond-mat/9902341
    \endverb
    \field{number}{arXiv:cond-mat/9902341}
    \field{title}{Predictive {{Information}}}
    \verb{url}
    \verb http://arxiv.org/abs/cond-mat/9902341
    \endverb
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/ZHN9WDLZ/Bialek and Tishby - 1999 - Predi
    \verb ctive Information.pdf
    \endverb
    \field{eprinttype}{arxiv}
    \field{day}{25}
    \field{month}{02}
    \field{year}{1999}
    \field{urlday}{17}
    \field{urlmonth}{05}
    \field{urlyear}{2022}
    \warn{\item Can't use 'eprinttype' + 'archiveprefix'}
  \endentry

  \entry{Lopez-Ruiz1995a}{article}{}
    \name{author}{3}{}{%
      {{hash=LRR}{%
         family={López-Ruiz},
         familyi={L\bibinithyphendelim R\bibinitperiod},
         given={R.},
         giveni={R\bibinitperiod},
      }}%
      {{hash=MHL}{%
         family={Mancini},
         familyi={M\bibinitperiod},
         given={H.\bibnamedelima L.},
         giveni={H\bibinitperiod\bibinitdelim L\bibinitperiod},
      }}%
      {{hash=CX}{%
         family={Calbet},
         familyi={C\bibinitperiod},
         given={X.},
         giveni={X\bibinitperiod},
      }}%
    }
    \strng{namehash}{LRR+1}
    \strng{fullhash}{LRRMHLCX1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{abstract}{%
    A measure of complexity based on a probabilistic description of physical
  systems is proposed. This measure incorporates the main features of the
  intuitive notion of such a magnitude. It can be applied to many physical
  situations and to different descriptions of a given system. Moreover, the
  calculation of its value does not require a considerable computational effort
  in many cases of physical interest. © 1995.%
    }
    \verb{doi}
    \verb 10.1016/0375-9601(95)00867-5
    \endverb
    \field{issn}{03759601}
    \field{number}{5-6}
    \field{pages}{321\bibrangedash 326}
    \field{title}{A Statistical Measure of Complexity}
    \field{volume}{209}
    \field{journaltitle}{Physics Letters A}
    \field{year}{1995}
  \endentry

  \entry{Virtanen2020}{article}{}
    \name{author}{1}{}{%
      {{hash=VP}{%
         family={Virtanen},
         familyi={V\bibinitperiod},
         given={Pauli},
         giveni={P\bibinitperiod},
      }}%
    }
    \strng{namehash}{VP1}
    \strng{fullhash}{VP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{pages}{15}
    \field{title}{{{SciPy}} 1.0: Fundamental Algorithms for Scientific
  Computing in {{Python}}}
    \field{volume}{17}
    \field{langid}{english}
    \verb{file}
    \verb /home/casper/Zotero/storage/Y4S98XZF/Virtanen - 2020 - SciPy 1.0 fund
    \verb amental algorithms for scientific c.pdf
    \endverb
    \field{journaltitle}{Nature Methods}
    \field{year}{2020}
  \endentry
\enddatalist
\endinput
